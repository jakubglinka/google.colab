{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertSequenceClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x7QLux38caQh",
        "6FtT5xQBu7tg",
        "JKqTVqyVxR2u"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubglinka/google.colab/blob/master/BertSequenceClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4AyWOwVo_gJ",
        "colab_type": "text"
      },
      "source": [
        "# Text Classification using BERT\n",
        "\n",
        " - training smaller Transformer from scratch\n",
        " - using pre-trained bert model\n",
        " - distil knowledge to smaller transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwrWFxeDr3-a",
        "colab_type": "text"
      },
      "source": [
        "## Configure environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDgjbvfoos5e",
        "colab_type": "code",
        "outputId": "17657690-eb55-4f10-f89b-656998ec778e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKMQ2ytGpSu1",
        "colab_type": "code",
        "outputId": "4fc04268-402a-45d6-9c96-47fc5f631c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Num GPUs Available:  1\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJJJylM2OBCa",
        "colab_type": "code",
        "outputId": "9c6a3cea-a9b8-414b-f2cf-a0a0834f9075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "try:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "except ValueError as error:\n",
        "  print(error)\n",
        "  print(\"No TPU available. Switching to single device strategy.\")\n",
        "  strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide a TPU Name to connect to.\n",
            "No TPU available. Switching to single device strategy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1GG_p1hrACo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install git+https://jbglin:botrx56jtlp6p2cbsthvt3bkslgeo3pzc5c7iuu4irxscjmmc6xa@dev.azure.com/eyDataScienceTeam/_git/nlp-ey-assets@develop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etw763McAqXP",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5jwC3wqa8c-",
        "colab_type": "text"
      },
      "source": [
        "### PolEmo data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lFdOILpAw91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pathlib\n",
        "import re\n",
        "import tqdm\n",
        "POLEMO_PATH = \"./drive/My Drive/sentiment/\"\n",
        "from typing import List\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe60MzVMCB44",
        "colab_type": "code",
        "outputId": "6129c96e-0d8b-4ed9-9793-0e265bfd5e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# read PolEmo data:\n",
        "def read_polemo_data(path) -> pd.DataFrame:\n",
        "  res = []\n",
        "  with path.open(\"r\") as f:\n",
        "    for line in f:\n",
        "      rec = line.strip(\"\\n\").split(\"__label__\")\n",
        "      rec[0] = rec[0].strip()\n",
        "      res.append(rec)\n",
        "\n",
        "  return pd.DataFrame(res, columns=[\"text\", \"label\"])\n",
        "\n",
        "df_train = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.train.txt\")\n",
        "print(f\"Read {df_train.shape[0]} train examples.\")\n",
        "\n",
        "df_dev = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.dev.txt\")\n",
        "print(f\"Read {df_dev.shape[0]} dev examples.\")\n",
        "\n",
        "df_test = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.test.txt\")\n",
        "print(f\"Read {df_test.shape[0]} test examples.\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 45974 train examples.\n",
            "Read 5747 dev examples.\n",
            "Read 5745 test examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Balu-CpqND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "2dc82841-eac7-4264-fcc6-83aa1beacfd0"
      },
      "source": [
        "df_train.iloc[5745, :]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text        Niestety mam podobne odczucia jak poprzedniczka .\n",
              "label                                               z_minus_m\n",
              "n_tokens                                                    7\n",
              "Name: 5745, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCcsjatvwvOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc = LabelEncoder().fit(df_train.label.values)\n",
        "\n",
        "# add encoded labels:\n",
        "df_train[\"label_enc\"] = enc.transform(df_train[\"label\"])\n",
        "df_dev[\"label_enc\"] = enc.transform(df_dev[\"label\"])\n",
        "df_test[\"label_enc\"] = enc.transform(df_test[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3pE8kKfrAeI",
        "colab_type": "code",
        "outputId": "6afadf68-1b7e-443f-d604-61b29b232669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# check for number of tokens ditribution\n",
        "df_train[\"n_tokens\"] = df_train.text.apply(lambda x: len(x.split()))\n",
        "np.quantile(df_train.n_tokens, q=[.9, .99, .999])"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 33.   ,  68.   , 128.027])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7QLux38caQh",
        "colab_type": "text"
      },
      "source": [
        "### Prepare `BertTokenizer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMCclM7UQ2mM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nlp.tokenizers import SentencePieceTokenizer\n",
        "from transformers import BertTokenizer\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.INFO)\n",
        "\n",
        "SP_TO_LOWER = False\n",
        "SP_MAX_VOCAB_SIZE = 2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvM0HTkya0KO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "c5aa5534-7499-4651-c96f-610a130c0d5a"
      },
      "source": [
        "# initialize tokenizer:\n",
        "tokenizer = SentencePieceTokenizer(lower=SP_TO_LOWER, strip_accents=SP_TO_LOWER)\n",
        "\n",
        "# prepare segments:\n",
        "segments = list(df_train.text) + list(df_dev.text) + list(df_test.text)\n",
        "\n",
        "# fit tokenizer:\n",
        "tokenizer.fit_on_segments(segments=segments, max_vocab_size=SP_MAX_VOCAB_SIZE)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████| 57466/57466 [00:05<00:00, 10660.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA-T5cdhJBHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "1ede0fb8-90e4-4006-8364-0723b69c3f75"
      },
      "source": [
        "# save vocabulary to disk in the format compatible with BertTokenizer:\n",
        "BERT_SPECIAL_TOKENS = [\"[PAD]\", \"[UNK]\", \"[SEP]\", \"[CLS]\", \"[MASK]\"]\n",
        "vocab = tokenizer.get_vocabulary()\n",
        "\n",
        "with pathlib.Path(\"./sentencepiece.vocab\").open(\"w\") as f:\n",
        "  for token in BERT_SPECIAL_TOKENS:\n",
        "    f.write(token + \"\\n\")\n",
        "  for idx, (word, __) in enumerate(vocab.items()):\n",
        "    if idx > 3:\n",
        "      if word.startswith(\"▁\"):\n",
        "        word = word.replace(\"▁\", \"\")\n",
        "      else:\n",
        "        word = \"##\" + word\n",
        "      f.write(word + \"\\n\")\n",
        "\n",
        "!head -n 7 ./sentencepiece.vocab"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD]\n",
            "[UNK]\n",
            "[SEP]\n",
            "[CLS]\n",
            "[MASK]\n",
            ".\n",
            "##a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxPC0t49TOVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "74bde770-ef80-4e73-c3f1-0a9a48c54cd0"
      },
      "source": [
        "# create new instance of BertTokenizer\n",
        "bert_tokenizer = BertTokenizer(\"./sentencepiece.vocab\", do_lower_case=SP_TO_LOWER, do_basic_tokenize=True)\n",
        "print(bert_tokenizer.tokenize(\"Ala ma kota!\"))\n",
        "\n",
        "# encode plus:\n",
        "bert_tokenizer.encode_plus(\"Ala ma kota!\", max_length=10, pad_to_max_length=True)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', '##la', 'ma', 'ko', '##ta', '!']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
              " 'input_ids': [3, 152, 86, 83, 253, 125, 59, 2, 0, 0],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ail5UJf4Ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from transformers import BertTokenizer\n",
        "\n",
        "# vocab = [\"byli\", \"##śmy\", \"Byli\", \"##smy\", \".\"]\n",
        "# with open(\"/tmp/test.vocab\", \"w\") as f:\n",
        "#   for wordpiece in vocab:\n",
        "#     f.write(wordpiece + \"\\n\")\n",
        "\n",
        "# bert_tokenizer = BertTokenizer(\"/tmp/test.vocab\", do_basic_tokenize=True, do_lower_case=True)\n",
        "# bert_tokenizer.tokenize(\"Byliśmy.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNOwG5D0yYad",
        "colab_type": "text"
      },
      "source": [
        "### TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8UUgNzMmWS6",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare single Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvZErYyfZz_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "7c38c3d2-5c45-4322-e2ea-68e29e0f58a2"
      },
      "source": [
        "bert_tokenizer.tokenize(\"za późno\")"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['za', 'późn', '##o']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQZiJc5lFqBF",
        "colab_type": "code",
        "outputId": "e84bc028-a8b5-4499-a2ab-57feecf50d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "from typing import Dict\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# prepare data:\n",
        "def _prepare_single_example(x: str, max_seq_len: int = None, label: int = 0) -> Dict:\n",
        "  \n",
        "  inputs = bert_tokenizer.encode_plus(x, max_length=max_seq_len, pad_to_max_length=False, return_tensors=\"tf\")\n",
        "  inputs[\"attention_mask\"] = tf.squeeze(inputs[\"attention_mask\"], axis=0)\n",
        "  inputs[\"input_ids\"] = tf.squeeze(inputs[\"input_ids\"], axis=0)\n",
        "  inputs[\"token_type_ids\"] = tf.squeeze(inputs[\"token_type_ids\"], axis=0)\n",
        "  \n",
        "  inputs[\"label\"] = tf.convert_to_tensor(label)\n",
        "  inputs[\"raw_text\"] = tf.convert_to_tensor(x)\n",
        "\n",
        "  return inputs\n",
        "\n",
        "# serialize:\n",
        "def _serialize_example(example):\n",
        "  \n",
        "  # attention mask\n",
        "  example[\"attention_mask\"] = tf.io.serialize_tensor(example[\"attention_mask\"]).numpy()\n",
        "  example[\"attention_mask\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"attention_mask\"]]))\n",
        "  \n",
        "  # input ids\n",
        "  example[\"input_ids\"] = tf.io.serialize_tensor(example[\"input_ids\"]).numpy()\n",
        "  example[\"input_ids\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"input_ids\"]]))\n",
        "\n",
        "  # token type ids\n",
        "  example[\"token_type_ids\"] = tf.io.serialize_tensor(example[\"token_type_ids\"]).numpy()\n",
        "  example[\"token_type_ids\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"token_type_ids\"]]))\n",
        "\n",
        "  example[\"raw_text\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"raw_text\"].numpy()]))\n",
        "  example[\"label\"] = tf.train.Feature(int64_list = tf.train.Int64List(value=[example[\"label\"].numpy()]))\n",
        "\n",
        "  ex = tf.train.Example(features=tf.train.Features(feature=example))\n",
        "  return ex.SerializeToString()  \n",
        "\n",
        "example = _prepare_single_example(\"Ala ma kota!\", 64, 1)\n",
        "example\n",
        "tf.train.Example.FromString(_serialize_example(example))"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "features {\n",
              "  feature {\n",
              "    key: \"attention_mask\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"\\010\\003\\022\\004\\022\\002\\010\\010\\\" \\001\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"input_ids\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"\\010\\003\\022\\004\\022\\002\\010\\010\\\" \\003\\000\\000\\000\\230\\000\\000\\000V\\000\\000\\000S\\000\\000\\000\\375\\000\\000\\000}\\000\\000\\000;\\000\\000\\000\\002\\000\\000\\000\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"label\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 1\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"raw_text\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"Ala ma kota!\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"token_type_ids\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"\\010\\003\\022\\004\\022\\002\\010\\010\\\" \\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FtT5xQBu7tg",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hCk4dGhesTQn",
        "colab": {}
      },
      "source": [
        "!rm ./train.TFRecord ./dev.TFRecord ./test.TFRecord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsff3xpKKzVa",
        "colab_type": "code",
        "outputId": "a2be2e1c-68c8-492c-8e95-f8f26db7e1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Write the `tf.Example` observations to the file.\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./train.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_train.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./dev.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_dev.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./test.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_test.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45974it [00:53, 854.15it/s]\n",
            "5747it [00:06, 821.78it/s]\n",
            "5745it [00:07, 819.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2iTdKDIBIuc",
        "colab_type": "code",
        "outputId": "b27104d5-fe0c-44d1-c7af-da5ca06a870f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "!ls -la -h | grep TF"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 3.9M Jan  3 20:39 dev.TFRecord\n",
            "-rw-r--r-- 1 root root 3.9M Jan  3 20:39 test.TFRecord\n",
            "-rw-r--r-- 1 root root  31M Jan  3 20:39 train.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKqTVqyVxR2u",
        "colab_type": "text"
      },
      "source": [
        "#### Copy to GC Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWvoy79zxXTk",
        "colab_type": "code",
        "outputId": "a96ef07d-4dd3-49b8-d01d-c087bb2c1398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'southern-shard-211411'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOHKKI9XxXS9",
        "colab_type": "code",
        "outputId": "3ffabd5e-532f-41ca-b1bb-2465b274773f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# Upload the files to a given Google Cloud Storage bucket.\n",
        "!gsutil cp ./train.TFRecord gs://tf_experiments_records/PolEmo/train.TFRecord\n",
        "!gsutil cp ./dev.TFRecord gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
        "!gsutil cp ./test.TFRecord gs://tf_experiments_records/PolEmo/test.TFRecord"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://./train.TFRecord [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/30.6 MiB.                                     \n",
            "Copying file://./dev.TFRecord [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/3.9 MiB.                                      \n",
            "Copying file://./test.TFRecord [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  3.8 MiB/  3.8 MiB]                                                \n",
            "Operation completed over 1 objects/3.8 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enJpe7ZBB8L8",
        "colab_type": "text"
      },
      "source": [
        "### Read from GC Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_6fyYLkybS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "b7b3bb4c-6805-4e30-dbbf-5bebeee4fac0"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'southern-shard-211411'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vldThzyv3iNy",
        "colab_type": "code",
        "outputId": "7e491656-de89-4fd3-d663-d5e017511bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Set access for the TPU pod:\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/train.TFRecord\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/test.TFRecord"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated ACL on gs://tf_experiments_records/PolEmo/train.TFRecord\n",
            "Updated ACL on gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
            "Updated ACL on gs://tf_experiments_records/PolEmo/test.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn3fKZtFC1MK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "39f40a5f-9d39-41bd-ee5f-593b97b26a9d"
      },
      "source": [
        "# Create a dictionary describing the features.\n",
        "_feature_description = {\n",
        "    'attention_mask': tf.io.FixedLenFeature([], tf.string),\n",
        "    'input_ids': tf.io.FixedLenFeature([], tf.string),\n",
        "    'token_type_ids': tf.io.FixedLenFeature([], tf.string),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "}\n",
        "\n",
        "def _parse_data(example_proto, max_seq_len: int = 128):\n",
        "  # Parse the input tf.Example proto using the dictionary above.\n",
        "  rec = tf.io.parse_single_example(example_proto, _feature_description)\n",
        "  \n",
        "  # attention_mask:\n",
        "  rec[\"attention_mask\"] = tf.io.parse_tensor(rec[\"attention_mask\"], out_type=tf.int32)\n",
        "  rec[\"attention_mask\"] = rec[\"attention_mask\"][:max_seq_len]\n",
        "  n_tokens = tf.shape(rec[\"attention_mask\"])[0]\n",
        "  padding = max_seq_len - n_tokens\n",
        "  rec[\"attention_mask\"] = tf.pad(rec[\"attention_mask\"], paddings=[[0, padding]])\n",
        "\n",
        "  # input_ids:\n",
        "  rec[\"input_ids\"] = tf.io.parse_tensor(rec[\"input_ids\"], out_type=tf.int32)\n",
        "  rec[\"input_ids\"] = rec[\"input_ids\"][:max_seq_len]\n",
        "  rec[\"input_ids\"] = tf.pad(rec[\"input_ids\"], paddings=[[0, padding]])\n",
        "  \n",
        "  # token_type_ids\n",
        "  rec[\"token_type_ids\"] = tf.io.parse_tensor(rec[\"token_type_ids\"], out_type=tf.int32)\n",
        "  rec[\"token_type_ids\"] = rec[\"token_type_ids\"][:max_seq_len]\n",
        "  rec[\"token_type_ids\"] = tf.pad(rec[\"token_type_ids\"], paddings=[[0, padding]])\n",
        " \n",
        "  # shape bug?\n",
        "  # rec[\"text/embedding\"] = tf.reshape(rec[\"text/embedding\"], [64, 256])\n",
        "  rec[\"attention_mask\"] = tf.reshape(rec[\"attention_mask\"], [max_seq_len, ])\n",
        "  rec[\"input_ids\"] = tf.reshape(rec[\"input_ids\"], [max_seq_len, ])\n",
        "  rec[\"token_type_ids\"] = tf.reshape(rec[\"token_type_ids\"], [max_seq_len, ])\n",
        " \n",
        "  labels = tf.one_hot(rec[\"label\"], depth=4)\n",
        "  inputs = rec\n",
        "  inputs.pop(\"label\")\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "train_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/train.TFRecord\", num_parallel_reads=4)\n",
        "example_proto = next(iter(train_raw))\n",
        "_parse_data(example_proto, max_seq_len=12)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'attention_mask': <tf.Tensor: shape=(12,), dtype=int32, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              "  'input_ids': <tf.Tensor: shape=(12,), dtype=int32, numpy=\n",
              "  array([  3, 778,  31, 232,  50,  73,  26,   8, 796, 224,  16, 165],\n",
              "        dtype=int32)>,\n",
              "  'token_type_ids': <tf.Tensor: shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>},\n",
              " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 1.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMDV4evZB7OS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "134fa61b-0987-42a6-f279-b24010c816c7"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/train.TFRecord\", num_parallel_reads=4)\n",
        "train_parsed = train_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True).shuffle(1024)\n",
        "train_parsed = train_parsed.prefetch(-1)\n",
        "\n",
        "inputs, labels = next(iter(train_parsed))\n",
        "\n",
        "dev_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/dev.TFRecord\", num_parallel_reads=4)\n",
        "dev_parsed = dev_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dev_parsed = dev_parsed.prefetch(-1)\n",
        "\n",
        "test_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/test.TFRecord\", num_parallel_reads=4)\n",
        "test_parsed = test_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_parsed = test_parsed.prefetch(-1)\n",
        "\n",
        "inputs"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'input_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
              " array([[   3,  837,   84, ...,    0,    0,    0],\n",
              "        [   3,  129, 1510, ...,    0,    0,    0],\n",
              "        [   3,  115,   33, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [   3, 1361,    9, ...,    0,    0,    0],\n",
              "        [   3,   63,  208, ...,    0,    0,    0],\n",
              "        [   3,  153,    9, ...,    0,    0,    0]], dtype=int32)>,\n",
              " 'token_type_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5p-vWgaJGms",
        "colab_type": "text"
      },
      "source": [
        "## Small Transformer\n",
        "\n",
        "### Architecture\n",
        "\n",
        "![alt text](https://miro.medium.com/max/3740/1*hC4zIxPPK9KGDu-OYUfnCQ.png)\n",
        "\n",
        "### Settings\n",
        "\n",
        "*   vocab_size: 4000\n",
        "*   hidden_size: 256\n",
        "*   num_hidden_layers: 4\n",
        "*   num_attention_heads: 4\n",
        "*   intermediate_size: 1024\n",
        "*   max_position_embeddings: 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bklz7tdEMG4_",
        "colab_type": "text"
      },
      "source": [
        "### `BertConfig`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRyVcCOxME8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertConfig\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "# new config\n",
        "config = BertConfig(vocab_size=2000, \n",
        "                    hidden_size=128, \n",
        "                    num_attention_heads=4, \n",
        "                    num_hidden_layers=4, \n",
        "                    intermediate_size=256, \n",
        "                    max_position_embeddings=128,\n",
        "                    num_labels=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y1fVwhNQz9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  tf.random.set_seed(1234)\n",
        "  model = TFBertForSequenceClassification(config)\n",
        "\n",
        "  initial_learning_rate = 1e-3\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "                metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjdVGQVWVha-",
        "colab_type": "code",
        "outputId": "48c56661-0f9e-4682-b6c1-2081f7dab437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "model.fit(train_parsed, validation_data=dev_parsed, epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1436/1436 [==============================] - 42s 29ms/step - loss: 0.7519 - categorical_accuracy: 0.7156 - val_loss: 0.8563 - val_categorical_accuracy: 0.6699\n",
            "Epoch 2/3\n",
            "1436/1436 [==============================] - 37s 26ms/step - loss: 0.7506 - categorical_accuracy: 0.7166 - val_loss: 0.8563 - val_categorical_accuracy: 0.6699\n",
            "Epoch 3/3\n",
            " 136/1436 [=>............................] - ETA: 57s - loss: 0.7348 - categorical_accuracy: 0.7273"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-GQ7ixFVl9Q",
        "colab_type": "code",
        "outputId": "a0b51cfe-395e-466e-859f-84cc905a8aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "model.summary()\n",
        "!nvidia-smi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  819328    \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  516       \n",
            "=================================================================\n",
            "Total params: 819,844\n",
            "Trainable params: 819,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykQFeeosdrYL",
        "colab_type": "text"
      },
      "source": [
        "### Model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5avWBTUz7-nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# y_pred\n",
        "y_pred = model.predict(test_parsed)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred\n",
        "\n",
        "# y_true\n",
        "y_true = []  \n",
        "for __, labels in test_parsed:\n",
        "  y_true += list(np.argmax(labels.numpy(), axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Q6FltSevhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "45ab3678-0525-4d18-c8be-7831d2b75a24"
      },
      "source": [
        "print(classification_report(y_true=y_true, y_pred=y_pred, digits=3))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.582     0.334     0.425       679\n",
            "           1      0.648     0.802     0.717      2119\n",
            "           2      0.717     0.679     0.697      1515\n",
            "           3      0.719     0.650     0.683      1415\n",
            "\n",
            "    accuracy                          0.677      5728\n",
            "   macro avg      0.666     0.616     0.630      5728\n",
            "weighted avg      0.676     0.677     0.669      5728\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JZ2G8qJgXmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction examples:\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXcJhsQ5WPvE",
        "colab_type": "text"
      },
      "source": [
        "## MultiHead Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLaUj6uNQPUY",
        "colab_type": "text"
      },
      "source": [
        "## With SP Tokenisation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2cKhzk2QZMo",
        "colab_type": "text"
      },
      "source": [
        "## Finetune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bscz6OhUQVD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers.modeling_tf_bert import TFBertForSequenceClassification\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oIqg2rl_pEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVjcYy398xfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = TFBertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=4)\n",
        "\n",
        "  initial_learning_rate = 1e-4\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "                metrics=[tf.keras.metrics.CategoricalAccuracy()])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGCWPrii_v91",
        "colab_type": "code",
        "outputId": "d4ca2242-e84b-47b0-f3f6-7cbb30fb9289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "TRAINING_EXAMPLES = 1000\n",
        "\n",
        "train_texts = df_train.text.values\n",
        "train_labels = df_train.label_enc\n",
        "\n",
        "# create tensorflow dataset:\n",
        "train_texts_encoded = [tokenizer.encode_plus(text, max_length=128, pad_to_max_length=True) \n",
        "                       for text in train_texts[:TRAINING_EXAMPLES]]\n",
        "\n",
        "train_text_dict = pd.DataFrame(train_texts_encoded)\n",
        "train_text_dict = {\"input_ids\": np.vstack(train_text_dict.input_ids.apply(np.array).values), \n",
        "                   \"atttention_mask\": np.vstack(train_text_dict.attention_mask.apply(np.array).values)}\n",
        "\n",
        "y = np.array(train_labels[:TRAINING_EXAMPLES])\n",
        "y = y.reshape(-1, 1)\n",
        "enc = OneHotEncoder().fit(y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P0vp3ERAmVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((train_text_dict, enc.transform(X=y).todense())).shuffle(1024).batch(64, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stSgBTqeAAqd",
        "colab_type": "code",
        "outputId": "63250a62-6ac7-48f7-9c28-66e747190cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model.fit(dataset, steps_per_epoch=625, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 625 steps\n",
            "Epoch 1/5\n",
            "  1/625 [..............................] - ETA: 6:50:31"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnavailableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnavailableError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6f8800ab4f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m625\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mUnavailableError\u001b[0m: Socket closed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJteFZvBAxPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}