{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_nkjp",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubglinka/google.colab/blob/master/word2vec_nkjp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Y3WWnFCXAbGo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CBOW word2vec model on National Korpus of Polish Language\n",
        "\n",
        "## Outline:\n",
        " \n",
        " - prepare data\n",
        " - train embeddings\n",
        " - train sentiment classifier\n",
        "\n",
        "Remarks: use Tensorflow 2.0:\n",
        "\n",
        "https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/effective_tf2.md\n",
        "\n",
        "### TODO's:\n",
        "  - nkjp class with following functionalities:\n",
        "    - download\n",
        "    - summary\n",
        "    - split into train, valid and test (using whole texts I guess) stratified by type of text\n",
        "    - generate random sample of n sentences (segment on the fly) from traning/test/validation part\n",
        "    - train segmentor\n",
        "    - prepare tokenisation\n",
        "  - sentencepeice tokenisation\n",
        "\n",
        "### Install dependencies:"
      ]
    },
    {
      "metadata": {
        "id": "y9oM_068wvpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install untangle tf-nightly-2.0-preview sentencepiece nltk wget tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1vG-a7jwMz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load corpus\n",
        "\n",
        "http://nkjp.pl/settings/papers/NKJP_ksiazka.pdf\n"
      ]
    },
    {
      "metadata": {
        "id": "eiPjiqUAmoaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import tqdm\n",
        "import os\n",
        "import wget\n",
        "import tarfile\n",
        "import untangle as unt\n",
        "from typing import List, Union, Tuple\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "class tqdm_wget_pbar:\n",
        "  def __enter__(self):\n",
        "    self.elapsed = None\n",
        "    self.tqdm = None\n",
        "    return self\n",
        "\n",
        "  def update(self, elapsed, total, done):\n",
        "    if self.tqdm is None:\n",
        "      self.tqdm = tqdm.tqdm(total=round(total / 1e6), unit=\"MB\", unit_scale=True)\n",
        "      self.tqdm.update(round(elapsed / 1e6, 2))\n",
        "      self.elapsed = elapsed\n",
        "    else:\n",
        "      self.tqdm.update(round((elapsed - self.elapsed) / 1e6, 5))\n",
        "      self.elapsed = elapsed\n",
        "\n",
        "  def __exit__(self, b, c, d):\n",
        "    self.tqdm.close()\n",
        "\n",
        "class NKJP:\n",
        " \n",
        "  def __init__(self, dir: str, url: str = None):\n",
        "    self.url = \"http://clip.ipipan.waw.pl/NationalCorpusOfPolish?action=AttachFile&do=get&target=NKJP-PodkorpusMilionowy-1.2.tar.gz\"\n",
        "    self.dir = dir\n",
        "  \n",
        "  def is_downloaded(self) -> bool:  \n",
        "    return os.path.exists(self.dir)\n",
        "  \n",
        "  def download(self):\n",
        "        \n",
        "    if self.is_downloaded() == False:\n",
        "      \n",
        "      os.mkdir(self.dir)\n",
        "      with tqdm_wget_pbar() as pbar:\n",
        "        _pbar = lambda elapsed, total, done: pbar.update(elapsed, total, done) \n",
        "        wget.download(url=self.url, \n",
        "                      out= self.dir + \"/nkjp.tar.gz\",\n",
        "                      bar=_pbar)      \n",
        "    else:\n",
        "      print(\"nkjp already downloaded, reusing...\")\n",
        "      \n",
        "    return self\n",
        "\n",
        "  def is_extracted(self):\n",
        "    nkjp_folders = [f for f in os.listdir(self.dir) if f != 'nkjp.tar.gz']\n",
        "    return len(nkjp_folders) > 0\n",
        "  \n",
        "  def extract(self):\n",
        "    \n",
        "    if self.is_extracted() == False:\n",
        "    \n",
        "      with tarfile.open(self.dir + \"/nkjp.tar.gz\") as tar:\n",
        "        tar.extractall(self.dir)\n",
        "      \n",
        "    else:\n",
        "      print(\"nkjp already extracted, reusing...\")\n",
        "      \n",
        "    return self\n",
        "  \n",
        "  def _get_text_stats(dir: str) -> List[Tuple[str, Union[str, int]]]:\n",
        "\n",
        "    if os.path.isdir(dir):\n",
        "      xml_header = unt.parse(dir + \"/header.xml\")\n",
        "      text_types = xml_header.teiHeader.profileDesc.textClass.catRef\n",
        "      text_types = [(xx['scheme'],xx['target']) for xx in text_types]\n",
        "\n",
        "      num_words = int(xml_header.teiHeader.fileDesc.extent.num['value'])\n",
        "\n",
        "      stats = text_types + [(\"words\", num_words)]\n",
        "      stats = dict(stats)\n",
        "\n",
        "\n",
        "    else:\n",
        "      stats = {}\n",
        "\n",
        "\n",
        "    return [dir, [stats.get(\"words\", None), \n",
        "                  stats.get(\"#taxonomy-NKJP-type\", None), \n",
        "                  stats.get(\"#taxonomy-NKJP-channel\", None)]]\n",
        "                           \n",
        "\n",
        "  def get_text_stats(self) -> pd.DataFrame:\n",
        "\n",
        "    nkjp_folders = [f for f in os.listdir(self.dir) if f not in ['nkjp.tar.gz']]\n",
        "    xx = [get_text_stats(\"./nkjp/\" + folder) for folder in nkjp_folders]\n",
        "    df = pd.DataFrame.from_items(xx, orient=\"index\", columns=['words', 'type', 'channel'])\n",
        "\n",
        "    return df\n",
        "      \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIokWLk4l3Hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### NKJP structure:\n",
        "\n",
        "Typ tekstu:\n",
        "1. Literatura piękna:\n",
        "    -  proza,\n",
        "    - poezja,\n",
        "    - dramat, \n",
        "2. literatura faktu,\n",
        "3. publicystyka i krótkie wiadomości prasowe,\n",
        "4. typ naukowo-dydaktyczny,\n",
        "5. typ informacyjno-poradnikowy,\n",
        "6. książka niebeletrystyczna niesklasyfikowana,\n",
        "7. inne teksty pisane\n",
        "     - typ urzędowo-kancelaryjny,\n",
        "     - teksty perswazyjne (ogłoszenia, reklamy, propaganda polityczna),\n",
        "     - krótkie teksty instruktażowe ,\n",
        "8. listy,\n",
        "9. Internet\n",
        "    - interaktywne strony WWW (fora, chaty, listy dyskusyjne itp.),\n",
        "    - statyczne strony WWW,\n",
        "10. teksty mówione konwersacyjne,\n",
        "11. teksty mówione medialne,\n",
        "12. teksty quasi-mówione."
      ]
    },
    {
      "metadata": {
        "id": "RNKaMEbv3E8A",
        "colab_type": "code",
        "outputId": "903a714f-1c1e-4bb8-87e4-47e5142053e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "cell_type": "code",
      "source": [
        "# !rm -rf nkjp* NKJP*\n",
        "# !ls\n",
        "\n",
        "nkjp = NKJP(\"./nkjp/\")\n",
        "nkjp = nkjp.download()\n",
        "nkjp = nkjp.extract()\n",
        "df = nkjp.get_text_stats()\n",
        "df.describe(include=\"all\")"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nkjp already downloaded, reusing...\n",
            "nkjp already extracted, reusing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>type</th>\n",
              "      <th>channel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3889.000000</td>\n",
              "      <td>3889</td>\n",
              "      <td>3889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>#typ_publ</td>\n",
              "      <td>#kanal_prasa_dziennik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1986</td>\n",
              "      <td>1744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>256.421702</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1126.625693</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>197.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>32566.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               words       type                channel\n",
              "count    3889.000000       3889                   3889\n",
              "unique           NaN         14                      8\n",
              "top              NaN  #typ_publ  #kanal_prasa_dziennik\n",
              "freq             NaN       1986                   1744\n",
              "mean      256.421702        NaN                    NaN\n",
              "std      1126.625693        NaN                    NaN\n",
              "min         0.000000        NaN                    NaN\n",
              "25%        47.000000        NaN                    NaN\n",
              "50%        55.000000        NaN                    NaN\n",
              "75%       197.000000        NaN                    NaN\n",
              "max     32566.000000        NaN                    NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "metadata": {
        "id": "xo5uBnusf4Ns",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentence generator\n",
        "## Segmentation reader:\n"
      ]
    },
    {
      "metadata": {
        "id": "gHe4B5YPljJd",
        "colab_type": "code",
        "outputId": "9295fe13-55c8-4260-d85d-c10445c8764a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "cell_type": "code",
      "source": [
        "import untangle as unt\n",
        "from untangle import Element\n",
        "import itertools\n",
        "from typing import Tuple, Dict, List\n",
        "import re\n",
        "from itertools import groupby\n",
        "from functools import reduce\n",
        "\n",
        "\n",
        "def try_or_none(el):\n",
        "    try:\n",
        "      res = [seg.seg for seg in el.s]\n",
        "    except:\n",
        "        res = None\n",
        "\n",
        "    return res \n",
        "  \n",
        "def _get_token(txt: str) -> Tuple[str, int, int]:\n",
        "  pattern = re.compile('\\((.*)\\)')\n",
        "  res = re.search(pattern, txt)[0].strip(\"()\").split(\",\")\n",
        "  return tuple(res)\n",
        "\n",
        "def _get_tokens(elts: List[Element]) -> Tuple[str, List[Tuple[int, int]]]:\n",
        "  tokens = [_get_token(el['corresp']) for el in elts]\n",
        "  id = tokens[0][0]\n",
        "  tokens = list(map(lambda x: (int(x[1]), int(x[2])), tokens))\n",
        "  return id, [tokens]\n",
        "\n",
        "\n",
        "def _merge(x, y):\n",
        "  return x[0], x[1] + y[1]\n",
        "  \n",
        "\n",
        "def get_tokens(dir: str) -> Dict[str, List[Tuple[int, int]]]:\n",
        "\n",
        "  xml_segs = unt.parse(dir + \"/ann_segmentation.xml\")\n",
        "  xml_segs = xml_segs.teiCorpus.TEI.text.body.p\n",
        "  xml_segs = list(itertools.chain(*[try_or_none(xx) for xx in xml_segs]))\n",
        "  xml_segs = [_get_tokens(xx) for xx in xml_segs]\n",
        "  xml_segs = [reduce(_merge, groups) for (key, groups) in groupby(xml_segs, lambda x: x[0])]\n",
        "  return dict(xml_segs)\n",
        "\n",
        "get_tokens(\"./nkjp/TochmanWsciekly/\")[\"txt_1.2-ab\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 4), (5, 1), (7, 4), (11, 1)],\n",
              " [(13, 1), (15, 2), (18, 6), (25, 9), (34, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "metadata": {
        "id": "upvu7-UhAwa-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text pre-processing:\n",
        "\n",
        "http://www.aclweb.org/anthology/P16-1162\n",
        "\n",
        "  - sentencepiece\n",
        "  - to train senence piece model we need to prepare ..."
      ]
    },
    {
      "metadata": {
        "id": "6M3sOcX_xP-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "0766979a-75ea-488e-caa4-3056e05e7c63"
      },
      "cell_type": "code",
      "source": [
        "# generate text file with tokenized sentences \n",
        "\n",
        "\n",
        "\n",
        "xx = list(get_texts(\"./nkjp/TochmanWsciekly/\").values())\n",
        "with open(\"texts.txt\", \"w\") as f:\n",
        "  for l in xx:\n",
        "    f.write(\"<s>\" + l + \"</s>\" + \"\\n\")\n",
        "  \n",
        "!cat texts.txt"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s>Tych, którzy krzyczą o homofobii, prawda w oczy kole.</s>\n",
            "<s>Kole i mnie. I ja jestem zaburzony.</s>\n",
            "<s>Niektórzy mówią, że od homoseksualizmu do pedofilii droga niedaleka. Nie wydaje mi się. Ja na chłopców nie patrzę. Mnie chłopcy nie interesują.</s>\n",
            "<s>Mnie się podobają dojrzali mężczyźni, śniadzi, wysocy, mocni. Ich szukam, ich potrzebuję.</s>\n",
            "<s>I to jest mała część prawdy, na początek.</s>\n",
            "<s>Odsunął mnie od siebie.</s>\n",
            "<s>Rok dla chłopaka to era.</s>\n",
            "<s>Po roku nie było go już w naszej parafii. Pojechał do Afryki pracować z chorymi na AIDS.</s>\n",
            "<s>Byłem zupełnie sam z moim pragnieniem męskiego dotyku.</s>\n",
            "<s>Ale nie pamiętam pierwszego seksu. To znaczy nie wiem, który był pierwszy. Chyba kiedy byłem już w seminarium.</s>\n",
            "<s>Ważny ślad, który zaprowadził nas donikąd. Ślepa uliczka - nikt w MZA Janka nie poznaje.</s>\n",
            "<s>Jan bardzo chce wiedzieć, kim jest, mieć na krzyżu nazwisko, kiedy przyjdzie jego czas. Ale nie boi się śmierci. Sądzi, że śmierci nie ma. Ciało, które ginie, jest jedynie opakowaniem dla duszy. Jan stanie przed Bogiem i będzie musiał świadomie odpowiedzieć za całe życie, cokolwiek w tym poprzednim się wydarzyło.</s>\n",
            "<s>Robi sobie herbatę, rozlewa na ceratę, rozsypuje cukier.</s>\n",
            "<s>Teraz idzie do łazienki. Tam zamiast deski klozetowej ma na muszli specjalną gumową poduszkę w kształcie podkowy. Bo nie potrafi usiąść normalnie na sedesie. Musi na niego skoczyć. Niejedną deskę w życiu w ten sposób połamał, nieraz pokaleczył sobie pośladki.</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fk1uoj_O3Nl5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate Skip-gram batches\n",
        "\n",
        "https://arxiv.org/abs/1310.4546"
      ]
    },
    {
      "metadata": {
        "id": "HgpmkKNw3dWw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Texts"
      ]
    },
    {
      "metadata": {
        "id": "3y-XuL6leOYk",
        "colab_type": "code",
        "outputId": "794d972d-f9ba-429d-fe6e-cdfc7b1ab4d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "# !ls ./nkjp/GazetaPomorska/\n",
        "\n",
        "# !head ./nkjp/TochmanWsciekly/text.xml -n 50\n",
        "# !head ./nkjp/TochmanWsciekly/ann_segmentation.xml -n 50\n",
        "\n",
        "import untangle as unt\n",
        "from typing import Dict\n",
        "import itertools\n",
        "\n",
        "def get_texts(dir: str) -> Dict[str, str]:\n",
        "  \n",
        "  xml_texts = unt.parse(dir + \"/text.xml\")\n",
        "  xml_texts = [xxx for xxx in xml_texts.teiCorpus.TEI.text.body.div]\n",
        "\n",
        "  def try_or_none(el):\n",
        "    try:\n",
        "      res = [(txt['xml:id'], txt.cdata) for txt in el.ab]\n",
        "    except:\n",
        "      try:\n",
        "        res = [(txt['xml:id'], txt.cdata) for txt in el.u]\n",
        "      except:\n",
        "        try:\n",
        "          res = [(txt['xml:id'], txt.cdata) for txt in el.p]\n",
        "        except:\n",
        "          res = None\n",
        "\n",
        "    return res \n",
        "\n",
        "  xml_texts = list(itertools.chain(*[try_or_none(xx) for xx in xml_texts]))\n",
        "  return dict(xml_texts)\n",
        "\n",
        "get_texts(\"./nkjp/TochmanWsciekly/\")[\"txt_1.2-ab\"]"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kole i mnie. I ja jestem zaburzony.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "metadata": {
        "id": "GoYuxk5KeARB",
        "colab_type": "code",
        "outputId": "c05dc621-512c-49cf-9453-720bcf222f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "4v4_OPFzM4qP",
        "colab_type": "code",
        "outputId": "24eebd9b-4c3d-4ed1-a7c7-961f6fe047be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151MB [00:11, 13.3MB/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.NKJP at 0x7f996e8c61d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "UPIdn6XyO5_q",
        "colab_type": "code",
        "outputId": "8a3c6e26-c95e-493a-b34f-4e4a7a57ecc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "UMycky9kOJPW",
        "colab_type": "code",
        "outputId": "521f1c6f-900e-4156-9a8b-1747ce04426c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "nkjp is None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "N_kAcwON4W4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"./nkjp/nkjp.tar.gz\")\n",
        "tar\n",
        "tar.extractall(\"./nkjp/\")\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4oanQJI15FOi",
        "colab_type": "code",
        "outputId": "bfd3fe05-64b1-42a3-dd7a-4082c9403d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "!ls ./nkjp/ | head -n 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "010-2-000000001\n",
            "030-2-000000001\n",
            "030-2-000000002\n",
            "030-2-000000003\n",
            "030-2-000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VrqFXh7cojSa",
        "colab_type": "code",
        "outputId": "7cd4bd73-3535-4bd7-a644-2a3ff861d541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "cell_type": "code",
      "source": [
        "!echo \"To jest mój tekst w języku Polskim .\" > text.txt\n",
        "!echo \"Zdanie drugie . To jest moje drugie zdanie .\" >> text.txt\n",
        "\n",
        "!echo \"To jest mój tekst w języku Polskim .\" > text2.txt\n",
        "\n",
        "\n",
        "!head text.txt"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To jest mój tekst w języku Polskim .\n",
            "Zdanie drugie . To jest moje drugie zdanie .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gOzAjkNqsOPF",
        "colab_type": "code",
        "outputId": "a1cb66c1-9566-4573-f27d-495bd1b1043f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RCbHdPhBYyw",
        "colab_type": "code",
        "outputId": "3a90a8be-0608-4970-beab-109ba6a2f7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "spm.SentencePieceTrainer.Train(\"--input=/content/texts.txt --model_prefix=m --vocab_size=100 --model_type=unigram\")\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(\"/content/m.model\")\n",
        "\n",
        "\n",
        "ids = sp.EncodeAsIds(\"\"\"To jest mój tekst w języku Polskim , słowo nieznane . \\n To jest drugie zdanie .\"\"\")\n",
        "print(ids)\n",
        "sp.DecodeIds(ids)\n",
        "\n",
        "# sp.EncodeAsPieces(\"This is a test\")"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 55, 4, 56, 3, 10, 65, 19, 3, 16, 8, 14, 15, 16, 3, 99, 3, 19, 26, 11, 9, 14, 13, 3, 87, 4, 42, 15, 36, 10, 3, 12, 31, 30, 4, 99, 4, 28, 11, 22, 5, 22, 8, 3, 6, 3, 55, 4, 56, 3, 18, 24, 13, 25, 21, 3, 11, 18, 5, 17, 3, 6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To jest mój tekst w języku Polskim , słowo nieznane . To jest drugie zdanie .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "metadata": {
        "id": "qhv0Fyhzu7Xf",
        "colab_type": "code",
        "outputId": "6d1346be-23ca-4820-ab2e-6c29257ccf8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "sp.id_to_piece(3)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "metadata": {
        "id": "lYL1xqMZ_mON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import untangle as unt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "80hdQQqF_tcS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download and extract korpus from ipipan website\n",
        "\n",
        "!wget \"http://clip.ipipan.waw.pl/NationalCorpusOfPolish?action=AttachFile&do=get&target=NKJP-PodkorpusMilionowy-1.2.tar.gz\" -O nkjp.tar.gz\n",
        "!mkdir nkjp\n",
        "!tar -C ./nkjp -zxf nkjp.tar.gz -o\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfT8kcCQ_34P",
        "colab_type": "code",
        "outputId": "0d53dfb0-aa57-4631-fa07-907b4e233ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1019
        }
      },
      "cell_type": "code",
      "source": [
        "!ls ./nkjp/ | head -n 2\n",
        "!cat ./nkjp/030-2-000000001/text.xml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "010-2-000000001\n",
            "030-2-000000001\n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<teiCorpus xmlns:xi=\"http://www.w3.org/2001/XInclude\" xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
            " <xi:include href=\"NKJP_1M_header.xml\"/>\n",
            " <TEI>\n",
            "  <xi:include href=\"header.xml\"/>\n",
            "  <text xml:id=\"txt_text\" xml:lang=\"pl\">\n",
            "   <body xml:id=\"txt_body\">\n",
            "    <div xml:id=\"txt_1-div\" decls=\"#h_1-bibl\">\n",
            "     <ab n=\"p882in890of:PWN:030-2-000000001\" xml:id=\"txt_1.1-ab\">Łzy padały na cremoński lakier. Szkoda, nie wolno było niszczyć przedmiotu, na który ojciec, biedaczysko, wydał całą schedę po Luizie... Otarła je lewą, umęczoną ręką.</ab>\n",
            "     <ab n=\"p883in891of:PWN:030-2-000000001\" xml:id=\"txt_1.2-ab\">Wszedł Adam. Zawiało wodą kwiatową Maréchal Niel. Starannie domykał drzwi za sobą.</ab>\n",
            "     <ab n=\"p884in892of:PWN:030-2-000000001\" xml:id=\"txt_1.3-ab\">Trwała dalej w bezruchu.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_2-div\" decls=\"#h_2-bibl\">\n",
            "     <ab n=\"p45in53of:PWN:030-2-000000001\" xml:id=\"txt_2.1-ab\">Pan dyrektor był nieobecny, a Róża stała pod piecem, czekając, kiedy panna Aniela Bądska ukończy gamy i zechce łaskawie zaakompaniować jedynej uczennicy papy \"Moment musical\" Szuberta. Jedynej uczennicy - pierwszej \"adeptce\" skrzypiec Warszawskiego Konserwatorium na Tamce. Czarnej, chudej dziewczynie z rumieńcami latającymi jak płomień po śniadych policzkach, z lśniącym długim warkoczem, z kacapską wymową i z niemodnym medalionem na szyi.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_3-div\" decls=\"#h_3-bibl\">\n",
            "     <ab n=\"p804in812of:PWN:030-2-000000001\" xml:id=\"txt_3.1-ab\">To wszystko było nowe. Nowe także były miesięczne wędrówki na grób męża i sjesty na cmentarnej ławeczce, ze wzrokiem żarliwie utkwionym w darninę. I łzy po nocach, i nasłuchiwanie, czy Stenia nie kaszle, i rumieńce wstydu, gdy pytano przy wnukach: a gdzież to pan zięć? a cóż to o panu inżynierze nie słychać?</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_4-div\" decls=\"#h_4-bibl\">\n",
            "     <ab n=\"p114in122of:PWN:030-2-000000001\" xml:id=\"txt_4.1-ab\">Prawie wesoła - dokończyła przy pomocy krokodyla zdejmowania chusty. Strzepnęła ją, złożyła, odniosła tamże, gdzie portrecik ojca.</ab>\n",
            "     <ab n=\"p115in123of:PWN:030-2-000000001\" xml:id=\"txt_4.2-ab\">Telefon zadzwonił, upudrowała się gorączkowo, przybrała oschły wyraz twarzy - może Marta? - i podeszła do aparatu. Ledwie zdjęła słuchawkę, Sabina przycwałowała słoniowym truchtem przez korytarz.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_5-div\" decls=\"#h_5-bibl\">\n",
            "     <ab n=\"p1275in1283of:PWN:030-2-000000001\" xml:id=\"txt_5.1-ab\">Róża milczała. Słuchała napomnień jak ptasiego szczebiotu, który do niczego nie obowiązuje, gdyż nic ludzkiego nie oznacza. Oczy powlekła biaława szklistość, co wzmogło tajemnicę spojrzenia. Wydawała się spoczywać po niezmiernym wysiłku - szczęśliwa ze zdobyczy, pewna własnej potęgi, wreszcie syta wiedzy i spokoju.</ab>\n",
            "     <ab n=\"p1276in1284of:PWN:030-2-000000001\" xml:id=\"txt_5.2-ab\">Uśmiechnęła się do córki ze swej błogiej dali.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_6-div\" decls=\"#h_6-bibl\">\n",
            "     <ab n=\"p100in108of:PWN:030-2-000000001\" xml:id=\"txt_6.1-ab\">Radio gra \"Close your eyes\". Róża - wzburzona pominięciem przez córkę swojej wizyty, zirytowana brakiem szacunku tutaj, w tym zięciowskim domu, dla empirowego stolika, zmęczona gniewem - usłyszała pieśń i pragnęła zapomnieć, jaki jest dzień, jaka sytuacja.</ab>\n",
            "     <ab n=\"p101in109of:PWN:030-2-000000001\" xml:id=\"txt_6.2-ab\">Zerknęła w lustro, obciągnęła na sobie sweter w czerwone skrzydła...</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_7-div\" decls=\"#h_7-bibl\">\n",
            "     <ab n=\"p1785in1793of:PWN:030-2-000000001\" xml:id=\"txt_7.1-ab\">Marta rzuciła telefon; stając na progu, stanęła twarzą w twarz z matką. Róża - wysoko osadzona - patrzyła przed siebie nad miarę otwartymi oczami. W tych oczach odbijał się widok nietutejszy. Źrenice usiłowały go ogarnąć w całej jego dzikiej wielkości, rozszerzały się, rosły ciągle Marta w smudze nieziemskiego widzenia szła ścierpnięta. Uklękła... Opasała ramionami duże, ciepłe ciało, przytuliła głowę do łona, które ją wydało światu.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_8-div\" decls=\"#h_8-bibl\">\n",
            "     <ab n=\"p1013in1021of:PWN:030-2-000000001\" xml:id=\"txt_8.1-ab\">W okresie szkolnym nie inaczej przedstawiała się sprawa koleżanek. Raz do roku tylko bywały zapraszane. Róża wtedy występowała ze wspaniałym przyjęciem. Stół uginał się pod tortami, owocami, kremami, z mebli zdejmowano pokrowce, srebra błyszczały, posadzki lśniły. Program zabawy był ściśle ustalony. Zazwyczaj latarnia czarnoksięska zajmowała gros czasu, później należało kolejno deklamować wiersze, godzinę trwał \"talar\" i \"pierścionek\", godzinę tańce, przeplatane grą w szarady i lemoniadę. O ósmej wieczór gości żegnano.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_9-div\" decls=\"#h_9-bibl\">\n",
            "     <ab n=\"p167in175of:PWN:030-2-000000001\" xml:id=\"txt_9.1-ab\">Ewa, Éveline - to było imię, które nadała jej Luiza, dla względów prestiżowych. Róża pamiętała dobrze ten dzień.</ab>\n",
            "     <ab n=\"p168in176of:PWN:030-2-000000001\" xml:id=\"txt_9.2-ab\">Jesienią w niedzielę szły z ciotką na obrzędowy spacer do Łazienek, placem Wareckim, ulicą Szpitalną, Bracką, Alejami... Dorożki i kabriolety turkotały po wyboistym bruku. W pojazdach piętrzyły się damy i dziewczynki, szumiące od krochmalu, od jedwabiu liberty, od ostrowłosej sztywnej wełny. Panowie w cylindrach i w melonikach tkwili bokiem na przednich ławeczkach.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_10-div\" decls=\"#h_10-bibl\">\n",
            "     <ab n=\"p1240in1248of:PWN:030-2-000000001\" xml:id=\"txt_10.1-ab\">Wówczas Martę strach przejął. Jak to? Więc śpiew córki przestał być własną sprawą Róży? Więc pojawiły się jakieś inne sprawy? Prawda: codzienny, nieubłagany przymus \"stąd dotąd, stąd dotąd masz się nauczyć, pamiętaj, żeby następnym razem nie powtórzył się ten błąd\" - jak gdyby chodziło o małą, bezwolną dziewczynę - to dokuczało Marcie do żywego. Ale mimo wszystkie bunty - niczego tak nie lubiła jak widzieć matkę szczęśliwą ze swojej przyczyny.</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_11-div\" decls=\"#h_11-bibl\">\n",
            "     <ab n=\"p921in929of:PWN:030-2-000000001\" xml:id=\"txt_11.1-ab\">Marta ciskała nuty, zamykała się z trzaskiem u siebie.</ab>\n",
            "     <ab n=\"p922in930of:PWN:030-2-000000001\" xml:id=\"txt_11.2-ab\">W ciągu następnych lekcyj rozbujanie frazy dawało się powściągnąć, także styl i barwę uczuciową poddawała Róża; a jednak ostateczny rezultat pracy zawierał w sobie ten urzekający pierwiastek - nowość, którą do trudu kompozytora i Róży dodawała Marta z zasobów własnego organizmu. Róża chwytała dziewczęce fluidy, przesączone w melodie, doznając głębokiego wzruszenia: \"Więc to jest Marta, więc taka jest córeczka Adama\".</ab>\n",
            "    </div>\n",
            "    <div xml:id=\"txt_12-div\" decls=\"#h_12-bibl\">\n",
            "     <ab n=\"p878in886of:PWN:030-2-000000001\" xml:id=\"txt_12.1-ab\">Róża opuściła ręce. Siadła - nogi drżały. Rzuciła smyczek...</ab>\n",
            "     <ab n=\"p879in887of:PWN:030-2-000000001\" xml:id=\"txt_12.2-ab\">Księżycowa orkiestra pod batutą Brahmsa grała dalej. Tylko na miejscu skrzypiec wystąpiła cisza - czarna jak zaskórna woda. Jeszcze tu i ówdzie błyskał refleks sola... cisza przecież czyniła się coraz głębsza, szersza i pochłaniała resztkę wibracji. Z wolna milkły także widmowe instrumenty. Po jednemu wsiąkały w próżnię... Chaos bezdźwięczny pokrył wreszcie harmonię.</ab>\n",
            "    </div>\n",
            "   </body>\n",
            "  </text>\n",
            " </TEI>\n",
            "</teiCorpus>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a7WzmYltBQsB",
        "colab_type": "code",
        "outputId": "971ac962-9c2e-428a-d309-c86a33177ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "xx = unt.parse(\"./nkjp/030-2-000000001/text.xml\")\n",
        "[xxx.cdata for xxx in xx.teiCorpus.TEI.text.body.div[11].ab]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Róża opuściła ręce. Siadła - nogi drżały. Rzuciła smyczek...',\n",
              " 'Księżycowa orkiestra pod batutą Brahmsa grała dalej. Tylko na miejscu skrzypiec wystąpiła cisza - czarna jak zaskórna woda. Jeszcze tu i ówdzie błyskał refleks sola... cisza przecież czyniła się coraz głębsza, szersza i pochłaniała resztkę wibracji. Z wolna milkły także widmowe instrumenty. Po jednemu wsiąkały w próżnię... Chaos bezdźwięczny pokrył wreszcie harmonię.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "w_XUO-mBwoZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OY6JLAEF9kb6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u5mI16Zi90CZ",
        "colab_type": "code",
        "outputId": "a8ae24ae-a9c2-46fc-e962-f9124bebcfbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-dev20190217'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "L7lFypis93ih",
        "colab_type": "code",
        "outputId": "232c0534-1880-4285-cec4-58a1cb760200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "x = tf.random.normal([2, 2])\n",
        "\n",
        "@tf.function\n",
        "def square(x: tf.Tensor) -> tf.Tensor:\n",
        "  return(tf.square(x))\n",
        "\n",
        "print(x)\n",
        "print(square(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0217 10:25:40.323168 140638079080320 tf_logging.py:161] Entity <function square at 0x7fe8b0f67f28> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY=5. Please report this to the AutoGraph team. Cause: Unexpected error transforming <function square at 0x7fe8b0f67f28>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: name 'tf' is not defined\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.15044403  1.6586291 ]\n",
            " [ 1.1326104  -1.2539116 ]], shape=(2, 2), dtype=float32)\n",
            "WARNING: Entity <function square at 0x7fe8b0f67f28> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY=5. Please report this to the AutoGraph team. Cause: Unexpected error transforming <function square at 0x7fe8b0f67f28>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: name 'tf' is not defined\n",
            "tf.Tensor(\n",
            "[[0.02263341 2.7510505 ]\n",
            " [1.2828064  1.5722944 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yRtP-jjx-8th",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??tf.function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNgZXpqk_eh6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}