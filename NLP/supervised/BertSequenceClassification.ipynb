{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertSequenceClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubglinka/google.colab/blob/master/NLP/supervised/BertSequenceClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4AyWOwVo_gJ",
        "colab_type": "text"
      },
      "source": [
        "# Text Classification using BERT\n",
        "\n",
        " - training smaller Transformer from scratch\n",
        " - using pre-trained bert model\n",
        " - distil knowledge to smaller transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwrWFxeDr3-a",
        "colab_type": "text"
      },
      "source": [
        "## Configure environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDgjbvfoos5e",
        "colab_type": "code",
        "outputId": "d332ef83-3a05-4322-8e2b-bfe959a064d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKMQ2ytGpSu1",
        "colab_type": "code",
        "outputId": "eecd9cd5-7684-4d96-d39d-cf25b27654a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Num GPUs Available:  0\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJJJylM2OBCa",
        "colab_type": "code",
        "outputId": "67091145-3f00-4069-9c21-2c7cbe5af887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "try:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "except ValueError as error:\n",
        "  print(error)\n",
        "  print(\"No TPU available. Switching to single device strategy.\")\n",
        "  strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system 10.51.20.234:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system 10.51.20.234:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.51.20.234:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.51.20.234:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1GG_p1hrACo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install git+https://jbglin:botrx56jtlp6p2cbsthvt3bkslgeo3pzc5c7iuu4irxscjmmc6xa@dev.azure.com/eyDataScienceTeam/_git/nlp-ey-assets@develop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etw763McAqXP",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5jwC3wqa8c-",
        "colab_type": "text"
      },
      "source": [
        "### PolEmo data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lFdOILpAw91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pathlib\n",
        "import re\n",
        "import tqdm\n",
        "POLEMO_PATH = \"./drive/My Drive/sentiment/\"\n",
        "from typing import List\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe60MzVMCB44",
        "colab_type": "code",
        "outputId": "1a68ed24-3034-4b9f-b437-ed3fd134115a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# read PolEmo data:\n",
        "def read_polemo_data(path) -> pd.DataFrame:\n",
        "  res = []\n",
        "  with path.open(\"r\") as f:\n",
        "    for line in f:\n",
        "      rec = line.strip(\"\\n\").split(\"__label__\")\n",
        "      rec[0] = rec[0].strip()\n",
        "      res.append(rec)\n",
        "\n",
        "  return pd.DataFrame(res, columns=[\"text\", \"label\"])\n",
        "\n",
        "df_train = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.train.txt\")\n",
        "print(f\"Read {df_train.shape[0]} train examples.\")\n",
        "\n",
        "df_dev = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.dev.txt\")\n",
        "print(f\"Read {df_dev.shape[0]} dev examples.\")\n",
        "\n",
        "df_test = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.test.txt\")\n",
        "print(f\"Read {df_test.shape[0]} test examples.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 45974 train examples.\n",
            "Read 5747 dev examples.\n",
            "Read 5745 test examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Balu-CpqND",
        "colab_type": "code",
        "outputId": "3a3ba0a3-02f8-41e3-d9bc-6c7f7142d6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "df_train.iloc[5745, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     Niestety mam podobne odczucia jak poprzedniczka .\n",
              "label                                            z_minus_m\n",
              "Name: 5745, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCcsjatvwvOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc = LabelEncoder().fit(df_train.label.values)\n",
        "\n",
        "# add encoded labels:\n",
        "df_train[\"label_enc\"] = enc.transform(df_train[\"label\"])\n",
        "df_dev[\"label_enc\"] = enc.transform(df_dev[\"label\"])\n",
        "df_test[\"label_enc\"] = enc.transform(df_test[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5p-vWgaJGms",
        "colab_type": "text"
      },
      "source": [
        "## Small Transformer\n",
        "\n",
        "### Architecture\n",
        "\n",
        "![alt text](https://miro.medium.com/max/3740/1*hC4zIxPPK9KGDu-OYUfnCQ.png)\n",
        "\n",
        "### Settings\n",
        "\n",
        "*   vocab_size: 4000\n",
        "*   hidden_size: 256\n",
        "*   num_hidden_layers: 4\n",
        "*   num_attention_heads: 4\n",
        "*   intermediate_size: 1024\n",
        "*   max_position_embeddings: 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7QLux38caQh",
        "colab_type": "text"
      },
      "source": [
        "### Prepare `BertTokenizer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMCclM7UQ2mM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nlp.tokenizers import SentencePieceTokenizer\n",
        "from transformers import BertTokenizer\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.INFO)\n",
        "\n",
        "SP_TO_LOWER = False\n",
        "SP_MAX_VOCAB_SIZE = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvM0HTkya0KO",
        "colab_type": "code",
        "outputId": "28ad2544-fa81-4599-c111-66763fe5a909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# initialize tokenizer:\n",
        "tokenizer = SentencePieceTokenizer(lower=SP_TO_LOWER, strip_accents=SP_TO_LOWER)\n",
        "\n",
        "# prepare segments:\n",
        "segments = list(df_train.text) + list(df_dev.text) + list(df_test.text)\n",
        "\n",
        "# fit tokenizer:\n",
        "tokenizer.fit_on_segments(segments=segments, max_vocab_size=SP_MAX_VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████| 57466/57466 [00:05<00:00, 11486.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA-T5cdhJBHF",
        "colab_type": "code",
        "outputId": "4ff98af2-f6b7-4c57-8f3f-f6d28ac9bf8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# save vocabulary to disk in the format compatible with BertTokenizer:\n",
        "BERT_SPECIAL_TOKENS = [\"[PAD]\", \"[UNK]\", \"[SEP]\", \"[CLS]\", \"[MASK]\"]\n",
        "vocab = tokenizer.get_vocabulary()\n",
        "\n",
        "with pathlib.Path(\"./sentencepiece.vocab\").open(\"w\") as f:\n",
        "  for token in BERT_SPECIAL_TOKENS:\n",
        "    f.write(token + \"\\n\")\n",
        "  for idx, (word, __) in enumerate(vocab.items()):\n",
        "    if idx > 3:\n",
        "      if word.startswith(\"▁\"):\n",
        "        word = word.replace(\"▁\", \"\")\n",
        "      else:\n",
        "        word = \"##\" + word\n",
        "      f.write(word + \"\\n\")\n",
        "\n",
        "!head -n 7 ./sentencepiece.vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD]\n",
            "[UNK]\n",
            "[SEP]\n",
            "[CLS]\n",
            "[MASK]\n",
            ".\n",
            ",\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxPC0t49TOVh",
        "colab_type": "code",
        "outputId": "ed73c1c0-4c57-4d42-c9dc-efbc3fad6079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "# create new instance of BertTokenizer\n",
        "bert_tokenizer = BertTokenizer(\"./sentencepiece.vocab\", do_lower_case=SP_TO_LOWER, do_basic_tokenize=True)\n",
        "print(bert_tokenizer.tokenize(\"Ala ma kota!\"))\n",
        "\n",
        "# encode plus:\n",
        "bert_tokenizer.encode_plus(\"Ala ma kota!\", max_length=10, pad_to_max_length=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Al', '##a', 'ma', 'kot', '##a', '!']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
              " 'input_ids': [3, 4126, 7, 66, 2121, 7, 40, 2, 0, 0],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNrJ2bZsWs_t",
        "colab_type": "code",
        "outputId": "f6eb2f2c-ec08-4c45-f4d2-c4643eca7269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# check for number of tokens distribution\n",
        "df_train[\"n_tokens\"] = df_train.text.apply(lambda x: len(bert_tokenizer.tokenize(x)))\n",
        "np.quantile(df_train.n_tokens, q=[.9, .99, .999])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 50.   , 103.   , 193.108])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ail5UJf4Ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from transformers import BertTokenizer\n",
        "\n",
        "# vocab = [\"byli\", \"##śmy\", \"Byli\", \"##smy\", \".\"]\n",
        "# with open(\"/tmp/test.vocab\", \"w\") as f:\n",
        "#   for wordpiece in vocab:\n",
        "#     f.write(wordpiece + \"\\n\")\n",
        "\n",
        "# bert_tokenizer = BertTokenizer(\"/tmp/test.vocab\", do_basic_tokenize=True, do_lower_case=True)\n",
        "# bert_tokenizer.tokenize(\"Byliśmy.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNOwG5D0yYad",
        "colab_type": "text"
      },
      "source": [
        "### TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8UUgNzMmWS6",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare single Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvZErYyfZz_h",
        "colab_type": "code",
        "outputId": "17d232c0-6d8e-4645-8346-09e5458430c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "bert_tokenizer.tokenize(\"za późno, polecam\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['za', 'późno', ',', 'polecam']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQZiJc5lFqBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Dict\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# prepare data:\n",
        "def _prepare_single_example(x: str, max_seq_len: int = None, label: int = 0) -> Dict:\n",
        "  \n",
        "  inputs = bert_tokenizer.encode_plus(x, max_length=max_seq_len, pad_to_max_length=False, return_tensors=\"tf\")\n",
        "  inputs[\"attention_mask\"] = tf.squeeze(inputs[\"attention_mask\"], axis=0)\n",
        "  inputs[\"input_ids\"] = tf.squeeze(inputs[\"input_ids\"], axis=0)\n",
        "  inputs[\"token_type_ids\"] = tf.squeeze(inputs[\"token_type_ids\"], axis=0)\n",
        "  \n",
        "  inputs[\"label\"] = tf.convert_to_tensor(label)\n",
        "  inputs[\"raw_text\"] = tf.convert_to_tensor(x)\n",
        "\n",
        "  return inputs\n",
        "\n",
        "# serialize:\n",
        "def _serialize_example(example):\n",
        "  \n",
        "  # attention mask\n",
        "  example[\"attention_mask\"] = tf.io.serialize_tensor(example[\"attention_mask\"]).numpy()\n",
        "  example[\"attention_mask\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"attention_mask\"]]))\n",
        "  \n",
        "  # input ids\n",
        "  example[\"input_ids\"] = tf.io.serialize_tensor(example[\"input_ids\"]).numpy()\n",
        "  example[\"input_ids\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"input_ids\"]]))\n",
        "\n",
        "  # token type ids\n",
        "  example[\"token_type_ids\"] = tf.io.serialize_tensor(example[\"token_type_ids\"]).numpy()\n",
        "  example[\"token_type_ids\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"token_type_ids\"]]))\n",
        "\n",
        "  example[\"raw_text\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value=[example[\"raw_text\"].numpy()]))\n",
        "  example[\"label\"] = tf.train.Feature(int64_list = tf.train.Int64List(value=[example[\"label\"].numpy()]))\n",
        "\n",
        "  ex = tf.train.Example(features=tf.train.Features(feature=example))\n",
        "  return ex.SerializeToString()  \n",
        "\n",
        "# example = _prepare_single_example(\"Ala ma kota!\", 64, 1)\n",
        "# example\n",
        "# tf.train.Example.FromString(_serialize_example(example))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FtT5xQBu7tg",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hCk4dGhesTQn",
        "colab": {}
      },
      "source": [
        "!rm ./train.TFRecord ./dev.TFRecord ./test.TFRecord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsff3xpKKzVa",
        "colab_type": "code",
        "outputId": "f73872d8-fcc1-4d78-d10a-c4ad609de7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Write the `tf.Example` observations to the file.\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./train.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_train.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./dev.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_dev.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./test.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_test.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45974it [05:52, 130.60it/s]\n",
            "5747it [00:43, 131.11it/s]\n",
            "5745it [00:46, 124.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2iTdKDIBIuc",
        "colab_type": "code",
        "outputId": "4c5acbbf-7c9b-4e47-dacd-f4e2dc08b66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "!ls -la -h | grep TF"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 3.4M Jan  4 12:59 dev.TFRecord\n",
            "-rw-r--r-- 1 root root 3.4M Jan  4 13:00 test.TFRecord\n",
            "-rw-r--r-- 1 root root  27M Jan  4 12:58 train.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKqTVqyVxR2u",
        "colab_type": "text"
      },
      "source": [
        "#### Copy to GC Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWvoy79zxXTk",
        "colab_type": "code",
        "outputId": "dad10c19-32c5-4f3e-a295-0b70f1f9251e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'southern-shard-211411'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOHKKI9XxXS9",
        "colab_type": "code",
        "outputId": "8596bf31-7b06-4e6b-e129-36f4f8196b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# Upload the files to a given Google Cloud Storage bucket.\n",
        "!gsutil cp ./train.TFRecord gs://tf_experiments_records/PolEmo/train.TFRecord\n",
        "!gsutil cp ./dev.TFRecord gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
        "!gsutil cp ./test.TFRecord gs://tf_experiments_records/PolEmo/test.TFRecord"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://./train.TFRecord [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/26.6 MiB.                                     \n",
            "Copying file://./dev.TFRecord [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  3.4 MiB/  3.4 MiB]                                                \n",
            "Operation completed over 1 objects/3.4 MiB.                                      \n",
            "Copying file://./test.TFRecord [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/3.3 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enJpe7ZBB8L8",
        "colab_type": "text"
      },
      "source": [
        "### Read from GC Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_6fyYLkybS0",
        "colab_type": "code",
        "outputId": "0a5e770b-0942-4ed9-a254-e15737a123a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'southern-shard-211411'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vldThzyv3iNy",
        "colab_type": "code",
        "outputId": "3b1696e8-275f-46cf-a2e8-a23e39b54587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Set access for the TPU pod:\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/train.TFRecord\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/test.TFRecord"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated ACL on gs://tf_experiments_records/PolEmo/train.TFRecord\n",
            "Updated ACL on gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
            "Updated ACL on gs://tf_experiments_records/PolEmo/test.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn3fKZtFC1MK",
        "colab_type": "code",
        "outputId": "7c102d15-801b-4d16-a5b0-9e69e3f119eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "# Create a dictionary describing the features.\n",
        "_feature_description = {\n",
        "    'attention_mask': tf.io.FixedLenFeature([], tf.string),\n",
        "    'input_ids': tf.io.FixedLenFeature([], tf.string),\n",
        "    'token_type_ids': tf.io.FixedLenFeature([], tf.string),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "}\n",
        "\n",
        "def _parse_data(example_proto, max_seq_len: int = 128):\n",
        "  # Parse the input tf.Example proto using the dictionary above.\n",
        "  rec = tf.io.parse_single_example(example_proto, _feature_description)\n",
        "  \n",
        "  # attention_mask:\n",
        "  rec[\"attention_mask\"] = tf.io.parse_tensor(rec[\"attention_mask\"], out_type=tf.int32)\n",
        "  rec[\"attention_mask\"] = rec[\"attention_mask\"][:max_seq_len]\n",
        "  n_tokens = tf.shape(rec[\"attention_mask\"])[0]\n",
        "  padding = max_seq_len - n_tokens\n",
        "  rec[\"attention_mask\"] = tf.pad(rec[\"attention_mask\"], paddings=[[0, padding]])\n",
        "\n",
        "  # input_ids:\n",
        "  rec[\"input_ids\"] = tf.io.parse_tensor(rec[\"input_ids\"], out_type=tf.int32)\n",
        "  rec[\"input_ids\"] = rec[\"input_ids\"][:max_seq_len]\n",
        "  rec[\"input_ids\"] = tf.pad(rec[\"input_ids\"], paddings=[[0, padding]])\n",
        "  \n",
        "  # token_type_ids\n",
        "  rec[\"token_type_ids\"] = tf.io.parse_tensor(rec[\"token_type_ids\"], out_type=tf.int32)\n",
        "  rec[\"token_type_ids\"] = rec[\"token_type_ids\"][:max_seq_len]\n",
        "  rec[\"token_type_ids\"] = tf.pad(rec[\"token_type_ids\"], paddings=[[0, padding]])\n",
        " \n",
        "  # shape bug?\n",
        "  # rec[\"text/embedding\"] = tf.reshape(rec[\"text/embedding\"], [64, 256])\n",
        "  rec[\"attention_mask\"] = tf.reshape(rec[\"attention_mask\"], [max_seq_len, ])\n",
        "  rec[\"input_ids\"] = tf.reshape(rec[\"input_ids\"], [max_seq_len, ])\n",
        "  rec[\"token_type_ids\"] = tf.reshape(rec[\"token_type_ids\"], [max_seq_len, ])\n",
        " \n",
        "  labels = tf.one_hot(rec[\"label\"], depth=4)\n",
        "  inputs = rec\n",
        "  inputs.pop(\"label\")\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "train_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/train.TFRecord\", num_parallel_reads=4)\n",
        "example_proto = next(iter(train_raw))\n",
        "_parse_data(example_proto, max_seq_len=12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'attention_mask': <tf.Tensor: shape=(12,), dtype=int32, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              "  'input_ids': <tf.Tensor: shape=(12,), dtype=int32, numpy=\n",
              "  array([  101, 38217, 11669, 57482, 14052, 10381, 42863, 10637, 10132,\n",
              "         37598,   117, 59685], dtype=int32)>,\n",
              "  'token_type_ids': <tf.Tensor: shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>},\n",
              " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 1.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMDV4evZB7OS",
        "colab_type": "code",
        "outputId": "3a8071e1-f438-4391-b0b3-a41c7f35f42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "BATCH_SIZE = 8*64\n",
        "STEPS_PER_EPOCH = int(np.floor(45000 / BATCH_SIZE))\n",
        "VALIDATION_STEPS = int(np.floor(5700 / BATCH_SIZE))\n",
        "\n",
        "print(f\"STEPS_PER_EPOCH: {STEPS_PER_EPOCH}\")\n",
        "print(f\"VALIDATION_STEPS: {VALIDATION_STEPS}\")\n",
        "\n",
        "train_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/train.TFRecord\", num_parallel_reads=1)\n",
        "train_parsed = train_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True).repeat(100)\n",
        "train_parsed = train_parsed.prefetch(-1)\n",
        "\n",
        "inputs, labels = next(iter(train_parsed))\n",
        "\n",
        "dev_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/dev.TFRecord\", num_parallel_reads=1)\n",
        "dev_parsed = dev_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dev_parsed = dev_parsed.prefetch(-1)\n",
        "\n",
        "test_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/test.TFRecord\", num_parallel_reads=1)\n",
        "test_parsed = test_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_parsed = test_parsed.prefetch(-1)\n",
        "\n",
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STEPS_PER_EPOCH: 87\n",
            "VALIDATION_STEPS: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': <tf.Tensor: shape=(512, 128), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'input_ids': <tf.Tensor: shape=(512, 128), dtype=int32, numpy=\n",
              " array([[   3,  593,   74, ...,    0,    0,    0],\n",
              "        [   3,  165,  169, ...,    0,    0,    0],\n",
              "        [   3,   52,    9, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [   3, 3727,   18, ...,    0,    0,    0],\n",
              "        [   3,   96,  202, ...,    0,    0,    0],\n",
              "        [   3,  128,   11, ...,    0,    0,    0]], dtype=int32)>,\n",
              " 'token_type_ids': <tf.Tensor: shape=(512, 128), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bklz7tdEMG4_",
        "colab_type": "text"
      },
      "source": [
        "### `BertConfig`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRyVcCOxME8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertConfig\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "# new config\n",
        "config = BertConfig(vocab_size=10000, output_hidden_states=False,\n",
        "                    hidden_size=128, \n",
        "                    num_attention_heads=4, \n",
        "                    num_hidden_layers=4, \n",
        "                    intermediate_size=256, \n",
        "                    max_position_embeddings=128,\n",
        "                    num_labels=4, \n",
        "                    hidden_dropout_prob=0.1, \n",
        "                    attention_probs_dropout_prob=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePv_p-7fJXtO",
        "colab_type": "text"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y1fVwhNQz9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  tf.random.set_seed(1234)\n",
        "  model = TFBertForSequenceClassification(config)\n",
        "\n",
        "  initial_learning_rate = 1e-3\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=STEPS_PER_EPOCH,\n",
        "    decay_rate=.9,\n",
        "    staircase=True)\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "                metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjdVGQVWVha-",
        "colab_type": "code",
        "outputId": "4790fcbd-9cc4-4621-80cb-2dcd42d7e6c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
        "model.fit(train_parsed, \n",
        "          validation_data=dev_parsed, \n",
        "          epochs=100, \n",
        "          steps_per_epoch=STEPS_PER_EPOCH, \n",
        "          validation_steps=VALIDATION_STEPS,\n",
        "          callbacks=[callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 87 steps, validate for 11 steps\n",
            "Epoch 1/100\n",
            "87/87 [==============================] - 27s 308ms/step - loss: 1.1414 - categorical_accuracy: 0.5081 - val_loss: 0.8950 - val_categorical_accuracy: 0.6644\n",
            "Epoch 2/100\n",
            "87/87 [==============================] - 4s 41ms/step - loss: 0.7831 - categorical_accuracy: 0.7069 - val_loss: 0.8502 - val_categorical_accuracy: 0.6880\n",
            "Epoch 3/100\n",
            "87/87 [==============================] - 3s 40ms/step - loss: 0.6361 - categorical_accuracy: 0.7682 - val_loss: 0.8810 - val_categorical_accuracy: 0.6863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d0e192940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-GQ7ixFVl9Q",
        "colab_type": "code",
        "outputId": "f9733a79-d82d-41e8-f012-263952534cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "model.summary()\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  1843328   \n",
            "_________________________________________________________________\n",
            "dropout_369 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  516       \n",
            "=================================================================\n",
            "Total params: 1,843,844\n",
            "Trainable params: 1,843,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykQFeeosdrYL",
        "colab_type": "text"
      },
      "source": [
        "### Model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5avWBTUz7-nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# y_pred\n",
        "y_pred = model.predict(test_parsed)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred\n",
        "\n",
        "# y_true\n",
        "y_true = []  \n",
        "for __, labels in test_parsed:\n",
        "  y_true += list(np.argmax(labels.numpy(), axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Q6FltSevhd",
        "colab_type": "code",
        "outputId": "d6c31d18-7aac-41a9-d1b5-1dab5133cd3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "print(classification_report(y_true=y_true, y_pred=y_pred, digits=3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.593     0.301     0.399       668\n",
            "           1      0.701     0.754     0.727      2087\n",
            "           2      0.730     0.703     0.716      1489\n",
            "           3      0.645     0.751     0.694      1388\n",
            "\n",
            "    accuracy                          0.686      5632\n",
            "   macro avg      0.667     0.627     0.634      5632\n",
            "weighted avg      0.682     0.686     0.677      5632\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO31_VSdjHbD",
        "colab_type": "text"
      },
      "source": [
        "### Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq1blgOozDOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encode label:\n",
        "def _one_hot(i: int, num_classes: int = 4):\n",
        "  res = np.zeros(num_classes)\n",
        "  res[i] = 1.0\n",
        "  return res\n",
        "\n",
        "df_dev[\"y_true\"] = df_dev.label_enc.apply(lambda i: _one_hot(i, 4)) \n",
        "\n",
        "# add prediction from the model\n",
        "def _predict(text: str):\n",
        "  inputs = bert_tokenizer.encode_plus(text, return_tensors=\"tf\")\n",
        "  probs = tf.math.softmax(model(inputs)[0]).numpy()[0, :]\n",
        "  return probs\n",
        "\n",
        "preds = []\n",
        "for text in tqdm.tqdm(df_dev.text):\n",
        "  preds.append(_predict(text))\n",
        "\n",
        "df_dev[\"y_pred\"] = preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmlYzNWm_7f5",
        "colab_type": "code",
        "outputId": "882f61e7-cb32-4cdf-8b3e-dc72876a02bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "def _error_rate(row):\n",
        "  if row.y_true[1]>0.0:\n",
        "    return 1-row.y_pred[1]\n",
        "  elif row.y_true[2]>0.0:\n",
        "    return 1-row.y_pred[2]\n",
        "  else:\n",
        "    return 0.0\n",
        "\n",
        "df_dev[\"err\"] = df_dev.apply(_error_rate, axis=1)\n",
        "df_dev = df_dev.sort_values(\"err\", ascending=False)\n",
        "df_dev.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_enc</th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_pred</th>\n",
              "      <th>err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1874</th>\n",
              "      <td>Uwazni ratownicy .</td>\n",
              "      <td>z_plus_m</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>[0.004129357, 0.016014097, 0.00275878, 0.97709...</td>\n",
              "      <td>0.997241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5066</th>\n",
              "      <td>Byli śmy w motelu 2 tygodnie i poznali śmy tam...</td>\n",
              "      <td>z_plus_m</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>[0.0034799564, 0.009125898, 0.002991515, 0.984...</td>\n",
              "      <td>0.997008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>W samym Lądku znam kilka lepszych lokalizacji ...</td>\n",
              "      <td>z_minus_m</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>[0.031171313, 0.0031939463, 0.95880556, 0.0068...</td>\n",
              "      <td>0.996806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3285</th>\n",
              "      <td>Terenu jest od groma , żeby to wykorzystać .</td>\n",
              "      <td>z_plus_m</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>[0.007189473, 0.03683861, 0.0033637963, 0.9526...</td>\n",
              "      <td>0.996636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>Operacja trwała prawie dwie godziny , dokładni...</td>\n",
              "      <td>z_minus_m</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>[0.033936813, 0.0034607756, 0.942804, 0.0197985]</td>\n",
              "      <td>0.996539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3412</th>\n",
              "      <td>Na plazy sporo turystów - więc gmina powinna z...</td>\n",
              "      <td>z_minus_m</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>[0.03559218, 0.003975829, 0.94529516, 0.01513677]</td>\n",
              "      <td>0.996024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1785</th>\n",
              "      <td>Jednak jestem teraz nowym , wolnym i lepszym c...</td>\n",
              "      <td>z_plus_m</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>[0.0074265497, 0.040466454, 0.004024108, 0.948...</td>\n",
              "      <td>0.995976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5218</th>\n",
              "      <td>Kiedyś była z rozwojem motorycznym za równieśn...</td>\n",
              "      <td>z_plus_m</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>[0.003062808, 0.0063026086, 0.0040465556, 0.98...</td>\n",
              "      <td>0.995953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2700</th>\n",
              "      <td>Kwestia meldunku w moim przypadku to około 2 m...</td>\n",
              "      <td>z_plus_m</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>[0.0045489008, 0.010592602, 0.0043412168, 0.98...</td>\n",
              "      <td>0.995659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4670</th>\n",
              "      <td>Obyśmy dożyli takich lekarzy w państwowej Służ...</td>\n",
              "      <td>z_plus_m</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>[0.0031189849, 0.00647472, 0.0044278484, 0.985...</td>\n",
              "      <td>0.995572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...       err\n",
              "1874                                 Uwazni ratownicy .  ...  0.997241\n",
              "5066  Byli śmy w motelu 2 tygodnie i poznali śmy tam...  ...  0.997008\n",
              "333   W samym Lądku znam kilka lepszych lokalizacji ...  ...  0.996806\n",
              "3285       Terenu jest od groma , żeby to wykorzystać .  ...  0.996636\n",
              "4840  Operacja trwała prawie dwie godziny , dokładni...  ...  0.996539\n",
              "3412  Na plazy sporo turystów - więc gmina powinna z...  ...  0.996024\n",
              "1785  Jednak jestem teraz nowym , wolnym i lepszym c...  ...  0.995976\n",
              "5218  Kiedyś była z rozwojem motorycznym za równieśn...  ...  0.995953\n",
              "2700  Kwestia meldunku w moim przypadku to około 2 m...  ...  0.995659\n",
              "4670  Obyśmy dożyli takich lekarzy w państwowej Służ...  ...  0.995572\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JZ2G8qJgXmj",
        "colab_type": "code",
        "outputId": "dcfa220a-687d-47a6-abd9-5906e4666ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# prediction examples with the biggest error:\n",
        "text = df_dev.loc[4670, \"text\"]\n",
        "\n",
        "def _predict(text: str):\n",
        "  inputs = bert_tokenizer.encode_plus(text, return_tensors=\"tf\")\n",
        "  probs = tf.math.softmax(model(inputs)[0]).numpy()[0, :]\n",
        "  return probs\n",
        "\n",
        "probs = _predict(text)\n",
        "probs\n",
        "idx = np.argmax(probs)\n",
        "idx\n",
        "\n",
        "print(f\"{bert_tokenizer.tokenize(text)}: {enc.classes_[idx]}, p={probs[idx]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ob', '##y', '##ś', '##my', 'do', '##ż', '##y', '##li', 'taki', '##ch', 'lekarz', '##y', 'w', 'państwow', '##ej', 'S', '##ł', '##u', '##ż', '##bie', 'Zdrowi', '##a', '.', '.', '.', '.']: z_zero, p=0.9859784245491028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fha1df-nFYvM",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Trained BERT\n",
        " - bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2cKhzk2QZMo",
        "colab_type": "text"
      },
      "source": [
        "### Prepare BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bscz6OhUQVD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oIqg2rl_pEj",
        "colab_type": "code",
        "outputId": "ab27ea08-53b7-4dcc-e45e-67e39c7a80dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "# create new instance of BertTokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "print(bert_tokenizer.tokenize(\"Ala ma kota!\"))\n",
        "\n",
        "# encode plus:\n",
        "bert_tokenizer.encode_plus(\"Ala ma kota!\", max_length=10, pad_to_max_length=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ala', 'ma', 'kota', '!']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
              " 'input_ids': [101, 56500, 10824, 16469, 106, 102, 0, 0, 0, 0],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj-uhTYHKv8v",
        "colab_type": "code",
        "outputId": "4d4c18ed-a8b6-48bc-8eef-96775bda2395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# check for number of tokens distribution\n",
        "df_train[\"n_tokens\"] = df_train.text.apply(lambda x: len(bert_tokenizer.tokenize(x)))\n",
        "np.quantile(df_train.n_tokens, q=[.9, .99, .999])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 59.   , 122.   , 243.027])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBVIKcIdLEra",
        "colab_type": "text"
      },
      "source": [
        "### TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMNT-yCCLfeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm ./train.TFRecord ./dev.TFRecord ./test.TFRecord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvmS29wjLhqQ",
        "colab_type": "code",
        "outputId": "1a662fcd-99d9-47c9-8942-ab48c766e332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Write the `tf.Example` observations to the file.\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./train.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_train.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./dev.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_dev.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n",
        "\n",
        "with tf.io.TFRecordWriter(\"./test.TFRecord\") as writer:\n",
        "  for __, row in tqdm.tqdm(df_test.iterrows()):\n",
        "    example = _prepare_single_example(row.text, None, row.label_enc)\n",
        "    writer.write(_serialize_example(example))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45974it [05:36, 136.46it/s]\n",
            "5747it [00:42, 135.57it/s]\n",
            "5745it [00:43, 133.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ5rzh4WMqdh",
        "colab_type": "code",
        "outputId": "9be54b06-f357-499b-ddae-aef56058537a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "!ls -la -h | grep TF"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 3.8M Jan  4 15:37 dev.TFRecord\n",
            "-rw-r--r-- 1 root root 3.8M Jan  4 15:38 test.TFRecord\n",
            "-rw-r--r-- 1 root root  30M Jan  4 15:36 train.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bw0XhqUMs1z",
        "colab_type": "text"
      },
      "source": [
        "### Copy to GC Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwTmLdzeNTGA",
        "colab_type": "code",
        "outputId": "45b3bd1b-7326-44cf-92d4-81fe557cf4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'southern-shard-211411'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOhEi5Z2NXiB",
        "colab_type": "code",
        "outputId": "e9285fad-cfa6-4dd1-e98f-352325903d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# Upload the files to a given Google Cloud Storage bucket.\n",
        "!gsutil cp ./train.TFRecord gs://tf_experiments_records/PolEmo/train.TFRecord\n",
        "!gsutil cp ./dev.TFRecord gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
        "!gsutil cp ./test.TFRecord gs://tf_experiments_records/PolEmo/test.TFRecord"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://./train.TFRecord [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/29.6 MiB.                                     \n",
            "Copying file://./dev.TFRecord [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  3.8 MiB/  3.8 MiB]                                                \n",
            "Operation completed over 1 objects/3.8 MiB.                                      \n",
            "Copying file://./test.TFRecord [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  3.7 MiB/  3.7 MiB]                                                \n",
            "Operation completed over 1 objects/3.7 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZBfoUbNNl-O",
        "colab_type": "text"
      },
      "source": [
        "### Read from GC Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf-KYJJENuKL",
        "colab_type": "code",
        "outputId": "406a257b-7b0f-4a0a-d94b-56c0666c3dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Set access for the TPU pod:\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/train.TFRecord\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
        "!gsutil acl ch -u service-495559152420@cloud-tpu.iam.gserviceaccount.com:READER gs://tf_experiments_records/PolEmo/test.TFRecord"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No changes to gs://tf_experiments_records/PolEmo/train.TFRecord\n",
            "No changes to gs://tf_experiments_records/PolEmo/dev.TFRecord\n",
            "No changes to gs://tf_experiments_records/PolEmo/test.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXBTueAHNp-f",
        "colab_type": "code",
        "outputId": "02e34ccf-0c95-493c-ff1e-6de786966a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "BATCH_SIZE = 8*32\n",
        "STEPS_PER_EPOCH = int(np.floor(45000 / BATCH_SIZE))\n",
        "VALIDATION_STEPS = int(np.floor(5700 / BATCH_SIZE))\n",
        "\n",
        "print(f\"STEPS_PER_EPOCH: {STEPS_PER_EPOCH}\")\n",
        "print(f\"VALIDATION_STEPS: {VALIDATION_STEPS}\")\n",
        "\n",
        "train_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/train.TFRecord\", num_parallel_reads=1)\n",
        "train_parsed = train_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True).repeat(100)\n",
        "train_parsed = train_parsed.prefetch(-1)\n",
        "\n",
        "inputs, labels = next(iter(train_parsed))\n",
        "\n",
        "dev_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/dev.TFRecord\", num_parallel_reads=1)\n",
        "dev_parsed = dev_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dev_parsed = dev_parsed.prefetch(-1)\n",
        "\n",
        "test_raw = tf.data.TFRecordDataset(\"gs://tf_experiments_records/PolEmo/test.TFRecord\", num_parallel_reads=1)\n",
        "test_parsed = test_raw.map(_parse_data).batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_parsed = test_parsed.prefetch(-1)\n",
        "\n",
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STEPS_PER_EPOCH: 175\n",
            "VALIDATION_STEPS: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': <tf.Tensor: shape=(256, 128), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'input_ids': <tf.Tensor: shape=(256, 128), dtype=int32, numpy=\n",
              " array([[  101, 38217, 11669, ...,     0,     0,     0],\n",
              "        [  101, 11791, 15905, ...,     0,     0,     0],\n",
              "        [  101,   160, 20728, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101, 11255, 56359, ...,     0,     0,     0],\n",
              "        [  101, 11255, 24378, ...,     0,     0,     0],\n",
              "        [  101, 32224, 10451, ...,     0,     0,     0]], dtype=int32)>,\n",
              " 'token_type_ids': <tf.Tensor: shape=(256, 128), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL97fVbGOND6",
        "colab_type": "text"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjTcYwZPOPsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  tf.random.set_seed(1234)\n",
        "  model = TFBertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', \n",
        "                                                          num_labels=4, \n",
        "                                                          hidden_dropout_prob=0.1, \n",
        "                                                          attention_probs_dropout_prob=0.1)\n",
        "\n",
        "  initial_learning_rate = 1e-5\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=STEPS_PER_EPOCH*10000,\n",
        "    decay_rate=.99,\n",
        "    staircase=True)\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "                metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3RwfR5sOiFL",
        "colab_type": "code",
        "outputId": "f0aae555-e1ec-4f28-82b8-d09cab684476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"/tmp/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor=\"val_loss\", save_best_only=True)\n",
        "model.fit(train_parsed, \n",
        "          validation_data=dev_parsed, \n",
        "          epochs=100,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH, \n",
        "          validation_steps=VALIDATION_STEPS,\n",
        "          callbacks=[callback, checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 175 steps, validate for 22 steps\n",
            "Epoch 1/100\n",
            "175/175 [==============================] - 122s 700ms/step - loss: 1.0060 - categorical_accuracy: 0.5900 - val_loss: 0.8127 - val_categorical_accuracy: 0.6848\n",
            "Epoch 2/100\n",
            "175/175 [==============================] - 51s 294ms/step - loss: 0.7532 - categorical_accuracy: 0.7144 - val_loss: 0.7469 - val_categorical_accuracy: 0.7136\n",
            "Epoch 3/100\n",
            "175/175 [==============================] - 51s 293ms/step - loss: 0.6640 - categorical_accuracy: 0.7537 - val_loss: 0.7211 - val_categorical_accuracy: 0.7377\n",
            "Epoch 4/100\n",
            "175/175 [==============================] - 47s 270ms/step - loss: 0.5941 - categorical_accuracy: 0.7817 - val_loss: 0.7370 - val_categorical_accuracy: 0.7362\n",
            "Epoch 5/100\n",
            "175/175 [==============================] - 47s 270ms/step - loss: 0.5421 - categorical_accuracy: 0.7996 - val_loss: 0.7690 - val_categorical_accuracy: 0.7228\n",
            "Epoch 6/100\n",
            "175/175 [==============================] - 47s 269ms/step - loss: 0.4864 - categorical_accuracy: 0.8233 - val_loss: 0.7997 - val_categorical_accuracy: 0.7260\n",
            "Epoch 7/100\n",
            "175/175 [==============================] - 47s 271ms/step - loss: 0.4522 - categorical_accuracy: 0.8362 - val_loss: 0.8189 - val_categorical_accuracy: 0.7193\n",
            "Epoch 8/100\n",
            "175/175 [==============================] - 47s 270ms/step - loss: 0.4129 - categorical_accuracy: 0.8511 - val_loss: 0.7940 - val_categorical_accuracy: 0.7381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f711f60b630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbNfbWU4zQIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/tmp/weights.03-0.72.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8KhMwcUzeAw",
        "colab_type": "code",
        "outputId": "e21154f1-5128-4417-d3e0-b7e03b0eea96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "model.evaluate(test_parsed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     22/Unknown - 6s 288ms/step - loss: 0.7014 - categorical_accuracy: 0.7406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7014398385177959, 0.7405895]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqCR7t0dRqlv",
        "colab_type": "text"
      },
      "source": [
        "### Model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8w8LG-kPnSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# y_pred\n",
        "y_pred = model.predict(test_parsed)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred\n",
        "\n",
        "# y_true\n",
        "y_true = []  \n",
        "for __, labels in test_parsed:\n",
        "  y_true += list(np.argmax(labels.numpy(), axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnwTECuLRtpq",
        "colab_type": "code",
        "outputId": "3c5479c8-f0bb-4154-bf52-54cc42337089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "print(classification_report(y_true=y_true, y_pred=y_pred, digits=3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.673     0.358     0.467       668\n",
            "           1      0.717     0.849     0.778      2087\n",
            "           2      0.753     0.770     0.762      1489\n",
            "           3      0.789     0.730     0.758      1388\n",
            "\n",
            "    accuracy                          0.741      5632\n",
            "   macro avg      0.733     0.677     0.691      5632\n",
            "weighted avg      0.739     0.741     0.732      5632\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZGtebI6aTHF",
        "colab_type": "code",
        "outputId": "8b4eceba-d777-4d7d-d7e3-971604f6a1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# prediction examples with the biggest error:\n",
        "text = \"Odsyłają z placówki na infolinię i z powrotem - bez sensu.\"\n",
        "\n",
        "def _predict(text: str):\n",
        "  inputs = bert_tokenizer.encode_plus(text, return_tensors=\"tf\")\n",
        "  probs = tf.math.softmax(model(inputs)[0]).numpy()[0, :]\n",
        "  return probs\n",
        "\n",
        "probs = _predict(text)\n",
        "probs\n",
        "idx = np.argmax(probs)\n",
        "idx\n",
        "\n",
        "print(f\"{bert_tokenizer.tokenize(text)}: {enc.classes_[idx]}, p={probs[idx]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Od', '##sy', '##ła', '##ją', 'z', 'pla', '##ców', '##ki', 'na', 'info', '##lini', '##ę', 'i', 'z', 'po', '##wr', '##ote', '##m', '-', 'bez', 'sensu', '.']: z_minus_m, p=0.7245222330093384\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}