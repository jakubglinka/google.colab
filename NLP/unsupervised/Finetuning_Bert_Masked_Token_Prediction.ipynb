{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning Bert: Masked Token Prediction",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhd0BdX7WZcbKW2Zrn6dSm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubglinka/google.colab/blob/master/NLP/unsupervised/Finetuning_Bert_Masked_Token_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inj4pQsmy0LM",
        "colab_type": "text"
      },
      "source": [
        "## Finetuning multilanguage BERT model on PolEmo data\n",
        " - whole word masking\n",
        " - training using gradient tape\n",
        " - checkpoint in GC\n",
        " - with new transformers tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wukZ7ttm3KdD",
        "colab_type": "text"
      },
      "source": [
        "### Configure environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMdvXqUf3Wuc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f1b2cbf7-8718-405b-9287-0e0cd2afc5be"
      },
      "source": [
        "# mount google drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTVTJZbZ_SSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "889b7bc2-86ac-4349-e3df-bb5eb852b159"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrBFZSZRybpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers tokenizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCAggvt63zur",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation\n",
        "#### PolEmo segments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsuNdFnI0X2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pathlib\n",
        "import re\n",
        "import tqdm\n",
        "POLEMO_PATH = \"./drive/My Drive/sentiment/\"\n",
        "from typing import List\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hIXC_Q93_rR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a55e0cd5-7d4e-4674-8841-02eb3710da4c"
      },
      "source": [
        "# read PolEmo data:\n",
        "def read_polemo_data(path) -> pd.DataFrame:\n",
        "  res = []\n",
        "  with path.open(\"r\") as f:\n",
        "    for line in f:\n",
        "      rec = line.strip(\"\\n\").split(\"__label__\")\n",
        "      rec[0] = rec[0].strip()\n",
        "      res.append(rec)\n",
        "\n",
        "  return pd.DataFrame(res, columns=[\"text\", \"label\"])\n",
        "\n",
        "df_train = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.train.txt\")\n",
        "print(f\"Read {df_train.shape[0]} train examples.\")\n",
        "\n",
        "df_dev = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.dev.txt\")\n",
        "print(f\"Read {df_dev.shape[0]} dev examples.\")\n",
        "\n",
        "df_test = read_polemo_data(pathlib.Path(POLEMO_PATH) / \"all.sentence.test.txt\")\n",
        "print(f\"Read {df_test.shape[0]} test examples.\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 45974 train examples.\n",
            "Read 5747 dev examples.\n",
            "Read 5745 test examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MheSK9a04Bex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "c6a4d967-7310-4c8e-ed5f-20e7da3e3140"
      },
      "source": [
        "segments = np.hstack([df_train.text.values, df_dev.text.values, df_train.text.values])\n",
        "total_tokens = np.sum([len(s.split()) for s in segments])\n",
        "print(f\"Read {len(segments)} segments with {total_tokens} tokens.\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 97695 segments with 1747153 tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6zHd7Jv4L35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "a3839e07-f029-467d-f9ad-ba7d4fb29695"
      },
      "source": [
        "segments[100]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'W tym przedziale cenowym to fajna opcja .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJXCi3Uk5A-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4dc9850a-69a1-422b-f2cc-1139fb552c7a"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForMaskedLM\n",
        "\n",
        "# create new instance of BertTokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "print(bert_tokenizer.tokenize(\"Ala ma kotka!\"))\n",
        "print(bert_tokenizer.tokenize(\"Ala ma [MASK] [MASK]!\"))\n",
        "\n",
        "# encode plus:\n",
        "inputs = bert_tokenizer.encode_plus(\"[MASK] została [MASK] zniszczona podczas II [MASK] światowej.\", \n",
        "                                    max_length=100, \n",
        "                                    pad_to_max_length=False, \n",
        "                                    return_tensors=\"tf\")\n",
        "print(inputs)\n",
        "\n",
        "# pre-trained model:\n",
        "# model = TFBertForMaskedLM.from_pretrained(\"bert-base-multilingual-cased\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ala', 'ma', 'kot', '##ka', '!']\n",
            "['Ala', 'ma', '[MASK]', '[MASK]', '!']\n",
            "{'input_ids': <tf.Tensor: shape=(1, 14), dtype=int32, numpy=\n",
            "array([[  101,   103, 14795,   103,   194, 12597, 10305, 37104, 16096,\n",
            "        10335,   103, 23524,   119,   102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 14), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 14), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICIuLoks-sTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "c026bdac-b120-43de-9edd-93be6bd20aab"
      },
      "source": [
        "inputs\n",
        "out = model(inputs)[0]\n",
        "ids = tf.argmax(out, axis=2)\n",
        "ids"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 14), dtype=int64, numpy=\n",
              "array([[  119, 53344, 14795, 75822,   194, 12597, 10305, 37104, 16096,\n",
              "        10335, 18396, 23524,   119, 50690]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5P9yxfNAHUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "834f17c3-18d1-4db1-f753-38ce11438685"
      },
      "source": [
        "bert_tokenizer.convert_ids_to_tokens(ids[0])"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.',\n",
              " 'Wieś',\n",
              " 'została',\n",
              " 'całkowicie',\n",
              " 'z',\n",
              " '##nis',\n",
              " '##z',\n",
              " '##czona',\n",
              " 'podczas',\n",
              " 'II',\n",
              " 'wojny',\n",
              " 'światowej',\n",
              " '.',\n",
              " 'Cho']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOSpzAXJTvIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "d63f83ed-4283-455f-d9c9-431d0e70d03f"
      },
      "source": [
        "mask_ids = tf.convert_to_tensor([[3]])\n",
        "mask_ids"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[3]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUw3YqlIgU88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "db37552e-d6ed-46b7-dc08-fc8df71e8261"
      },
      "source": [
        "out\n",
        "tf.gather(params=out, indices=mask_ids, axis=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10, 119547), dtype=float32, numpy=\n",
              "array([[[-8.676005 , -8.609662 , -8.704817 , ..., -8.566978 ,\n",
              "         -8.410093 , -8.558181 ],\n",
              "        [-7.1411476, -6.984398 , -6.697263 , ..., -6.875798 ,\n",
              "         -6.037149 , -7.6966734],\n",
              "        [-8.6006155, -8.013317 , -8.075018 , ..., -7.3978434,\n",
              "         -6.664183 , -8.906027 ],\n",
              "        ...,\n",
              "        [-6.447791 , -6.2427697, -6.0470066, ..., -6.369944 ,\n",
              "         -5.53222  , -7.3532   ],\n",
              "        [-6.5746155, -6.3526473, -6.129633 , ..., -6.3965993,\n",
              "         -5.628853 , -7.49408  ],\n",
              "        [-6.9921584, -6.7348404, -6.437596 , ..., -6.7293444,\n",
              "         -5.965511 , -8.072048 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNUyJ_85jJyz",
        "colab_type": "text"
      },
      "source": [
        "### Prepare masked LM data:\n",
        "https://github.com/google-research/bert/blob/master/create_pretraining_data.py  \n",
        "https://github.com/google-research/bert/blob/cc7051dc592802f501e8a6f71f8fb3cf9de95dc9/run_pretraining.py#L273\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq3Hd7yZs7UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_len = 128               # maximum tokens per sequence\n",
        "max_predictions_per_seq = 20    # maximum number of predictions per single sentence\n",
        "duplication_factor = 10         # duplication factor of trining data (with different masking)\n",
        "masked_lm_prob = .15            # probability of masking a token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-vkGwEtxShA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "f4851400-69f6-4a9c-beb3-27d8f5090821"
      },
      "source": [
        "# single example blueprint:\n",
        "# text: Ala ma kota!\n",
        "# tokens:         [CLS] Ala ma [MASK] ! [SEP] [PAD] [PAD]\n",
        "# input_ids:       101  xxx xx  103   x  102    0     0\n",
        "# attention_mask:   1    1  1    1    1   1     0     0\n",
        "# token_type_ids:   0    0  0    0    0   0     0     0\n",
        "# masked_positions: [3, 0, 0, ...]\n",
        "# masked_labels:    [16469, 0, 0, ...]\n",
        "# label_weights:    [1.0, 0.0, ...]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [101, 56500, 10824, 103, 106, 102],\n",
              " 'special_tokens_mask': [1, 0, 0, 0, 0, 1],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5wcTnQrgl5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "86f9c145-329c-48f5-9a65-586318b9675d"
      },
      "source": [
        "segment = \"Ala ma rudego kota!\"\n",
        "tokens = bert_tokenizer.tokenize(\"Ala ma rudego kota!\")\n",
        "print(tokens)\n",
        "bert_tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ala', 'ma', 'rud', '##ego', 'kota', '!']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[56500, 10824, 101701, 12419, 16469, 106]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRLxsxUsoYDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model\n",
        "model.save_pretrained(\"./model/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJnwCe_31zTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "f0ecaf1a-d3df-4662-d339-0c40cccfdcb5"
      },
      "source": [
        "!ls ./model"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.json  tf_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXwFLZgR2EFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "1de403c1-fc07-467c-cb13-e59795a1c599"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "TFBertForSequenceClassification.from_pretrained(\"./model\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.modeling_tf_bert.TFBertForSequenceClassification at 0x7ff03c6d9b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGhDgxvj2DIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "074619f7-3487-4ac2-e17b-5c06c0c94cd6"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids(\"[CLS] [MASK] [MASK] [SEP] [PAD] [PAD]\".split())"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 103, 103, 102, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2eJpEHEBJri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "56b271ea-a469-434c-de38-63a79341ee77"
      },
      "source": [
        "import random\n",
        "rng = random.Random(1234)\n",
        "rng.randint(0, 10)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdSwNOIlCbfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}